[
  {
    "objectID": "posts/2023-10-01-BIDEN-binary-inference-dictionaries-for-electoral-nlp/index.html",
    "href": "posts/2023-10-01-BIDEN-binary-inference-dictionaries-for-electoral-nlp/index.html",
    "title": "BIDEN: Binary Inference Dictionaries for Electoral NLP",
    "section": "",
    "text": "This post is adapted from a Jupyter Notebook found on GitHub.\nBIDEN: Binary Inference Dictionaries for Electoral NLP demonstrates a compression-based binary classification technique that is fast at both training and inference on common CPU hardware in Python. It is largely built on the strategies presented by FTCC, which in turn, was a reaction to Low-Resource Text Classification: A Parameter-Free Classification Method with Compressors (the gzip method). Like FTCC, BIDEN is built atop of Zstandard (Zstd), which leverages dictionary compression. Zstd dictionary compression seeds a compressor with sample data, so that it can efficiently compress small data (~1 KB) of similar composition. Seeding the compressor dictionaries acts as our “training” method for the model.\nThe BIDEN model was trained on the ElectionEmails 2020 data set — a database of over 900,000 political campaign emails from the 2020 US election cycle. In compliance with the data set’s terms, the training data is NOT provided with this repository. If you would like to train the BIDEN model yourself, you can request a copy of the data for free. The BIDEN model was trained on corpus_v1.0.\n\nTraining and Classification\nBoth training and inference for BIDEN are fast and simple.\nThe model consists of two Zstd compressors, one optimized for Democratic emails and one optimzed for Republican emails. Each is built upon a compression dictionary. Each compression dictionary is seeded with training sample emails from its respective party.\nClassification (inference) is achieved by compressing a test sample with both the Democratic and Republican compressors. Whichever compressor achieves a higher compression ratio on the test sample text is considered the inferred label.\n\n\nCleaning the Training Data\nThe ElectionEmails 2020 data set is a CSV. The model consideres two columns: party_affiliation and body_text. BIDEN is only concerned with binary classification for Democratic and Republican labeling.\nThe two requirements defined in requirements.txt are Pandas and zstandard:\npandas==2.1.*\nzstandard==0.21.* \nStart by reading in the data. Since the model is only working with two columns, drop any record that doesn’t contain both. Also filter the data to only consider Democratic or Republican emails for the binary classificaiton.\nNote: this assumes you have the ElectionEmails 2020 data saved at the relative path data/corpus_v1.0.csv.\n\nfrom enum import Enum\n\nimport pandas as pd\nimport zstandard\n\nfields = {\n    'body_text': str,\n    'party_affiliation': str,\n}\n\ndf = pd.read_csv(\n    'data/corpus_v1.0.csv',\n    sep=',',\n    usecols=list(fields.keys()),\n    dtype=fields,\n)\n\ndf.drop_duplicates(inplace=True)\n\nd_df = df[df.party_affiliation == \"Democratic Party\"].dropna()\nr_df = df[df.party_affiliation == \"Republican Party\"].dropna()\n\nprint(f'D Samples: {len(d_df.index)}')\nprint(f'R Samples: {len(r_df.index)}')\n\nD Samples: 127194\nR Samples: 36788\n\n\nThere are significantly more Democratic samples than Republican samples, so take a random subset of the former.\n\nmax_data = min(len(d_df.index), len(r_df.index))\nd_df = d_df.sample(\n    n=max_data,\n    random_state=9001  # random seed set for reproducibility \n).reset_index(drop=True)\n\nr_df = r_df.sample(\n    n=max_data,\n    random_state=9001  # random seed set for reproducibility \n).reset_index(drop=True)\n\nprint(f'D Samples: {len(d_df.index)}')\nprint(f'R Samples: {len(r_df.index)}')\n\nD Samples: 36788\nR Samples: 36788\n\n\nNow divide the data into training and test subsets, at an 80/20 split.\n\nd_train_df = d_df.sample(frac=0.8, random_state=9001)  # random seed set for reproducibility \nd_test_df = d_df.drop(d_train_df.index)\n\nr_train_df = r_df.sample(frac=0.8, random_state=9001)  # random seed set for reproducibility \nr_test_df = r_df.drop(r_train_df.index)\n\nprint(f'Democratic Training Samples: {len(d_train_df.index)}')\nprint(f'Democratic Test Samples: {len(d_test_df.index)}')\nprint(f'Republican Training Samples: {len(r_train_df.index)}')\nprint(f'Republican Test Samples: {len(r_test_df.index)}')\n\nDemocratic Training Samples: 29430\nDemocratic Test Samples: 7358\nRepublican Training Samples: 29430\nRepublican Test Samples: 7358\n\n\n\n\nThe BIDEN model\nThe model consistes of two core methods: train() and classify() :\n\nclass BIDEN():\n    \"\"\"\n    Binary Inference Dictionaries for Electoral NLP (BIDEN)\n\n    This class allows you to train a model for classifying political content into\n    Democratic or Republican categories based on compression ratios.\n\n    Attributes:\n        Classification (enum): An enumeration of political classifications (DEMOCRATIC, REPUBLICAN).\n    \"\"\"\n    class Classification(Enum):\n        \"\"\"\n        Enumeration of political classifications.\n\n        Attributes:\n            DEMOCRATIC (int): Represents Democratic political content.\n            REPUBLICAN (int): Represents Republican political content.\n        \"\"\"\n        DEMOCRATIC = 1\n        REPUBLICAN = 2\n        \n    def __init__(self, encoding: str = 'utf-8'):\n        \"\"\"\n        Initialize the BIDEN model.\n\n        This constructor initializes the BIDEN model with empty compressors.\n\n        Args:\n            encoding (str, optional): The character encoding of the input data. Defaults to 'utf-8'.\n            \n        Returns:\n            BIDEN: An instance of the BIDEN class.\n        \"\"\"\n        self.d_compressor = None\n        self.d_compressor = None\n        self.encoding = encoding\n\n    @property\n    def trained(self) -&gt; bool:\n        \"\"\"\n        Check if the BIDEN model is trained.\n\n        Returns:\n            bool: True if both Democratic and Republican compressors are trained, False otherwise.\n        \"\"\"\n        return bool(self.d_compressor and self.r_compressor)\n\n    def train(self,\n              d_training_data: str,\n              r_training_data: str,\n              compression_level: int = 15,\n             ) -&gt; bool:\n        \"\"\"\n        Train the BIDEN model.\n\n        Args:\n            d_training_data (str): Democratic training data.\n            r_training_data (str): Republican training data.\n            compression_level (int, optional): The compression level. Defaults to 15.\n\n        Returns:\n            bool: True if training is successful, False otherwise.\n        \"\"\"        \n        d_dictionary = zstandard.ZstdCompressionDict(\n            d_training_data.encode(self.encoding),\n            dict_type=zstandard.DICT_TYPE_RAWCONTENT\n        )\n        d_dictionary.precompute_compress(level=compression_level)\n        self.d_compressor = zstandard.ZstdCompressor(dict_data=d_dictionary)\n\n        r_dictionary = zstandard.ZstdCompressionDict(\n            r_training_data.encode(self.encoding),\n            dict_type=zstandard.DICT_TYPE_RAWCONTENT\n        )\n        r_dictionary.precompute_compress(level=compression_level)\n        self.r_compressor = zstandard.ZstdCompressor(dict_data=r_dictionary)\n\n        return self.trained\n\n    def classify(self, sample: str) -&gt; Classification:\n        \"\"\"\n        Classify a sample based on compression ratios.\n\n        Args:\n            sample (str): The sample text to classify.\n\n        Returns:\n            Classification: The classification (DEMOCRATIC or REPUBLICAN).\n        \n        Raises:\n            RuntimeError: If the model is not trained.\n        \"\"\"\n        if not self.trained:\n            raise RuntimeError(\"Attempted to classify with a model that is not yet trained.\")\n        \n        encoded_sample = sample.encode(self.encoding)\n        original_length = len(encoded_sample)\n        d_compressed_length = len(self.d_compressor.compress(encoded_sample))\n        d_ratio = d_compressed_length / original_length\n        r_compressed_length = len(self.r_compressor.compress(encoded_sample))\n        r_ratio = r_compressed_length / original_length\n\n        if r_ratio &lt; d_ratio:\n            return BIDEN.Classification.REPUBLICAN\n\n        return BIDEN.Classification.DEMOCRATIC\n\n\n\nTrain the Model\nTo train the model, we pass the entirety of the Democratic and Republican texts to construct prefix dictionaries. Prefix dictionaries allow compression operations to reference raw data within the dictionary. Once we have two compressors instantiated and pre-seeded with our training data, the model is trained. This is fast. On my 2.6 GHz 6-Core Intel Core i7, this takes roughly 30 seconds.\n\nd_combined_text = '\\n'.join(d_train_df.body_text)\nr_combined_text = '\\n'.join(r_train_df.body_text)\n\nmodel = BIDEN()\nmodel.train(d_combined_text, r_combined_text)\n\nTrue\n\n\n\n\nClassification\nNow, we can classify our test data. We could loop through each set, but let’s combine and shuffle them together first, and loop in one go. We’ll also convert the party affiliation strings 'Democratic Party', and 'Republican Party' into our model’s enum values:\n\ncombined_test_df = pd.concat(\n    [d_test_df, r_test_df],\n    ignore_index=True,\n    sort=False\n).sample(\n    frac=1,\n    random_state=9001,  # random seed set for reproducibility\n).reset_index(drop=True)\n\ncombined_test_df['party_affiliation'] = combined_test_df['party_affiliation'].replace(\n    to_replace=['Democratic Party', 'Republican Party'],\n    value=[BIDEN.Classification.DEMOCRATIC, BIDEN.Classification.REPUBLICAN]\n)\n\nnum_correct = 0\nfor row in combined_test_df.itertuples():\n    actual_label = row.party_affiliation\n    inferred_label = model.classify(row.body_text)\n\n    if inferred_label == actual_label:\n        num_correct += 1\n\nprint(f'Classification Success Rate: {((num_correct / len(combined_test_df.index))*100):.1f}%')\n\nClassification Success Rate: 98.9%\n\n\n98.9% is a shockingly high success rate for such a simple classification method!\n\n\nAnother Email Data Set\nLet’s see how it performs with emails from another data set. Derek Willis maintains a Datasette of over 150,000 campaign emails. Let’s grab 100 samples of each party from that collection, and see how they perform:\n\nbase_url = 'https://political-emails.herokuapp.com/emails.csv?sql='\nd_query = 'select body, party from emails where party = \"D\" limit 100;'\nr_query = 'select body, party from emails where party = \"R\" limit 100;'\n\nmap = {\n    ' ': '+',\n    ',': '%2C',\n    '=': '%3D',\n    '\"': '%22',\n    ';': '%3B',\n}\n\nfor symbol, code in map.items():\n    d_query = d_query.replace(symbol, code)\n    r_query = r_query.replace(symbol, code)\n\nd_url = base_url + d_query\nr_url = base_url + r_query\n\nd_dw_df = pd.read_csv(d_url)\nr_dw_df = pd.read_csv(r_url)\n\ncombined_dw_df = pd.concat(\n    [d_dw_df, r_dw_df],\n    ignore_index=True,\n    sort=False\n).sample(\n    frac=1,\n    random_state=9001,  # random seed set for reproducibility\n).reset_index(drop=True)\n\ncombined_dw_df['party'] = combined_dw_df['party'].replace(\n    to_replace=['D', 'R'],\n    value=[BIDEN.Classification.DEMOCRATIC, BIDEN.Classification.REPUBLICAN]\n)\n\nprint('DW Sample:')\ncombined_dw_df.head(10)\n\nDW Sample:\n\n\n\n\n\n\n\n\n\nbody\nparty\n\n\n\n\n0\nHey Peter!!! You know our campaign is made by,...\nClassification.DEMOCRATIC\n\n\n1\nhttps://www.jahanahayes.com/ [https://www.jaha...\nClassification.DEMOCRATIC\n\n\n2\nHi there, it’s storytime: I developed a keen n...\nClassification.DEMOCRATIC\n\n\n3\nWe’re contacting a select group of patriots fo...\nClassification.REPUBLICAN\n\n\n4\nPeter – You need to watch this. CLICK HERE OR ...\nClassification.REPUBLICAN\n\n\n5\nPeter, you may have seen me asking for your ol...\nClassification.DEMOCRATIC\n\n\n6\nDo you want an Official Mugshot Mug? (24-hour ...\nClassification.REPUBLICAN\n\n\n7\nhttps://secure.actblue.com/donate/cdp-footer?r...\nClassification.DEMOCRATIC\n\n\n8\n[ https://act.katieporter.com/go/14559?t=1001&...\nClassification.DEMOCRATIC\n\n\n9\nI hope I made you proud fighting for you at th...\nClassification.REPUBLICAN\n\n\n\n\n\n\n\n\nnum_correct = 0\nfor row in combined_dw_df.itertuples():\n    actual_label = row.party\n    inferred_label = model.classify(row.body)\n\n    if inferred_label == actual_label:\n        num_correct += 1\n\nprint(f'Classification Success Rate: {((num_correct / len(combined_dw_df.index))*100):.1f}%')\n\nClassification Success Rate: 93.0%\n\n\n93% is still quite good considering that all we’re doing is compression!\n\n\nClassifying Tweets\nThe Twitter API is basically useless these days, so I scrolled the timelines of Mike Pence (R) and Gavin Newsom (D), and copy+paste’d 5 tweets from each. It’s a tiny sample, and not really random, but it’s neat to see how well it does:\n\npence_tweets = [\n    # https://twitter.com/Mike_Pence/status/1707882018258751915\n    \"Today, we applaud the Eighth Circuit's decision, \" \\\n    \"which is an important step in the fight to uphold and protect \" \\\n    \"the rights of parents and families in Linn-Mar. A family is the \" \\\n    \"single best unit to protect children, and we must continue to do \" \\\n    \"everything we can to empower parents over bureaucrats. The strength \" \\\n    \"of our nation is tied to the strength of our families, and we will \" \\\n    \"not stand idly by as the Radical Left attempts to indoctrinate our \" \\\n    \"children behind parents’ backs.\",\n    # https://twitter.com/Mike_Pence/status/1707472823269392643\n    \"The cause of Life is the calling of our time \" \\\n    \"and I couldn’t be more proud to have played a role in the administration \" \\\n    \"that appointed three of the justices that overturned Roe v. Wade and \" \\\n    \"returned the question of abortion to the states and the American people.\",\n    \"Republicans are facing a Time for Choosing. \" \\\n    # https://twitter.com/Mike_Pence/status/1707241587460186214\n    \"We have to choose whether or not we’re going to stay on the path \" \\\n    \"that has defined our movement since the days of Ronald Reagan and \" \\\n    \"through the Trump-Pence years or whether we’re going to follow \" \\\n    \"the siren song of populism unmoored to Conservative principles.\",\n    # https://twitter.com/Mike_Pence/status/1704132623617122719\n    \"I am for working Americans and free enterprise. These businesses \" \\\n    \"make their decisions, but at the end the of the day these businesses \" \\\n    \"are responding to the heavy hand of the green new deal agenda of \" \\\n    \"Joe Biden and the Democrats in Washington, DC.\",\n    # https://twitter.com/Mike_Pence/status/1703887286641873137\n    \"We were the first country to sanction Chinese leaders for building \" \\\n    \"concentration camps in Xinjiang and for undermining democracy in Hong Kong. \" \\\n    \"And we stood up to years of trade abuses, and imposed historic tariffs \" \\\n    \"to bring China to the negotiating table.\"\n]\n\n[model.classify(t) for t in pence_tweets]\n\n[&lt;Classification.REPUBLICAN: 2&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;]\n\n\n\nnewsom_tweets = [\n    # https://twitter.com/GavinNewsom/status/1700615276667294035\n    \"When people ask why I am introducing a Constitutional Amendment \" \\\n    \"on gun safety this is why. Not only has Congress stalled for YEARS on passing \" \\\n    \"common sense reforms -- judges across the country are tearing down laws that \" \\\n    \"Americans overwhelmingly support. Laws that keep us SAFE and keep guns out of \" \\\n    \"the hands of dangerous criminals. We have to push back\",\n    # # https://twitter.com/GavinNewsom/status/1689743766733877248\n    \"California will be sending search and rescue \" \\\n    \"teams to assist in Hawaii's recovery efforts. The wildfires and \" \\\n    \"devastation that Maui is experiencing is all too familiar and all \" \\\n    \"too horrifying. We stand at the ready to aid Hawaii in its time of need.\",\n    # https://twitter.com/GavinNewsom/status/1679579172690329601\n    \"A school board in Temecula decided to reject a \" \\\n    \"textbook because it mentioned Harvey Milk. CA is stepping in. \" \\\n    \"We’re going to purchase the book for these students—the same \" \\\n    \"one that hundreds of thousands of kids are already using. \" \\\n    \"If these extremist school board members won’t do their job, \" \\\n    \"we will — and fine them for their incompetence.\",\n    # https://twitter.com/GavinNewsom/status/1650634702271942656\n    \"North Dakota GOP have decided to force women to give birth. Even victims of rape. \" \\\n    \"Meanwhile, they voted against providing school meals because child hunger isn't \" \\\n    \"\\\"the responsibility of the state.\\\"\" \\\n    \"Mandating birth is state responsibility. Helping feed those kids is not. Got it.\",\n    # https://twitter.com/GavinNewsom/status/1643745476662132737\n    \"Met with some librarians today while in Florida. \" \\\n    \"They shared with me the rich, diverse background of the \" \\\n    \"town and what's at stake if we ban our kids from learning our real history.\"\n]\n\n[model.classify(t) for t in newsom_tweets]\n\n[&lt;Classification.DEMOCRATIC: 1&gt;,\n &lt;Classification.DEMOCRATIC: 1&gt;,\n &lt;Classification.DEMOCRATIC: 1&gt;,\n &lt;Classification.DEMOCRATIC: 1&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;]\n\n\nNeat! This small set classified 90% correctly. Further exploration with more robust Twitter data sets is warranted.\n\n\nClosing Thoughts\nEven after seeing the results, I still have a hard time believing that this works so well! It feels like it shouldn’t work at all. But, zooming out, there are a lot of relevant factors to consider. First, there just aren’t that many people writing campaign materials. It makes sense that word-choice and writing style would exhibit predictible patterns. Second, campaign emails have been A/B tested into oblivion, so there’s a systematic process that cranks out similar-sounding copy. Third, the recipients of these emails have largely self-sorted. This likely bolsters the expected structure and copy uniquely for each label. Ultimately, compression algorithms optimize on patterns and predictibility. What this shows us is that the two parties are uniquely predictible in their written communications.\nThe idea of classification by compression is not new; Russell and Norvig wrote about it in 1995 in the venerable Artificial Intelligence: A Modern Approach:\n\n\n\nClassification by data compression\n\n\nMore recently, the “gzip beats BERT” paper got a lot of attention. What the BIDEN model demonstrates is that this technique is effective and likely generalizable on modern partisan texts.\nIt’s worth articulating again how fast and simple this method is. No GPUs. No Neural Networks. No N-grams. No transformers. No kNN.\nI think that’s pretty cool!\n\n\nLicense\nCopyright (c) 2023, Matt Hodges\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of BIDEN: Binary Inference Dictionaries for Electoral NLP nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "posts/2020-11-10-thank-you/index.html",
    "href": "posts/2020-11-10-thank-you/index.html",
    "title": "Thank you.",
    "section": "",
    "text": "It can’t be a cliche because it actually can’t be over-said: working on the Biden Campaign has been both the hardest and most rewarding experience of my career. It’s a rare opportunity to work on something you care deeply about, with amazing people, and to succeed. I said it in 2016, and in 2018, and I’ll say it again in 2020: the tech was never the point. I’m immensely proud of the work we did. The world will never fully understand the mountains that this scrappy team was able to move.\nTo those who invited me in: thank you. To those who pushed me: thank you. To those who pushed with me: thank you.\nWhat’s next? I’m going to sleep for a while. I don’t know what’s after that, but I won’t be stepping away from the fight for democracy, justice, and a better world."
  },
  {
    "objectID": "posts/2022-08-06-neural-network-from-scratch-python-numpy/index.html",
    "href": "posts/2022-08-06-neural-network-from-scratch-python-numpy/index.html",
    "title": "Building a Neural Network From Scratch with NumPy",
    "section": "",
    "text": "This post is adapted from a Jupyter Notebook found on GitHub.\nThe goal of this post is to give a hands-on explanation of how Artificial Neural Networks work. I intentionally avoided frameworks like PyTorch or Tensoflow because I wanted to build a better understanding of what Machine Learning models actually are, what Neural Networks actually are, and how they can be made. This post is a collection of information I wish I had when I began this journey. It touches on a little bit of the math, but I don’t deeply re-explain the math. I try to link out to more explanatory sources where I think it’s valuable. Note: I am not a Machine Learning engineer, nor am I a Data Scientist. I’m a Software Engineer that turned into a political operative (lol). I wrote this for an audience of Software Engineers. Also: I don’t have a GPU and I don’t want to spend a bunch of money renting one from Amazon. This model can be trained and deployed on a modern CPU in a matter of minutes.\n\nWhat We’ll Be Doing\nWe’re going to build a Neural Network for multi-class classification. All that means is we’re going to make a model takes in images and attempts to label them from a set of options. In our case, we’re going to create a Neural Network that works with the MNIST database of handwritten digits. This database contains 70,000 images of handwritten digits, 0 - 9, and corresponding labels of which digit the handwritten image is. We’ll use 60,000 of the images to train our Neural Network, and 10,000 to test its accuracy. The rest of this post assumes you have the data downloaded to a local data/ directory.\nNeural Networks are particularly handy for image classification tasks. There are many other types of Machine Learning out there, but we won’t spend any attention on those.\n\n\nBackground Concepts\n\nShape of a Neural Network\nFirst of all, let’s demystify one thing: Neural Networks are just graphs. Just nodes and edges. If you’ve studied any Computer Science or have a background in Software Engineering, this is probably a familiar conecpet to you. The exact shape of any given Neural Network is dependant on how you build it, but that’s something we get to decide. The graph has an input layer that is usually one node per input feature. In our case, a pixel of an image is a feature. Next, there are one or more hidden layers. Hidden layers are simply nodes in the graph that are in the middle. They take inputs from other nodes, and the give outputs to other nodes. This is the part that makes it Deep Learning. The presence of one or more hidden layers is the “deep” in Deep Learning. There’s no standard rule for the size of a hidden layer, or how many you should have. Finally, there’s an output layer. Each node in the output layer corresponds to one label. For example, if a possible label to an image is “cat” then one node in the output layer represents “cat”. We’re going to make a Neural Network that has a bunch of input layer nodes, a single hidden layer with ten nodes, and an output layer with ten nodes, one for each digit 0 - 9.\nEach Nueron (node) has a unique Weight and Bias, and each layer has an Activation Function. The Activation Function defines the output of a neuron given its inputs, and does not change. We’ll talk more about Activation Functions below. As we train our model, we adjust the Weights and Biases.\nHere’s are drawing of a Neural Network with three input nodes, a hidden layer with four nodes, and an output layer with two nodes. This might be how you’d construct a Neural Network that does binary classification: a model that tries to label inputs to one of two options for outputs.\n\n\n\n\n\n\n\n\nen:User:Cburnett, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\nIf you’re looking for more explanation of the structure of Neural Networks, “But what is a Neural Network?” by 3Blue1Brown is excellent.\n\n\nHow the Neural Network Learns\nNeural Networks start out very stupid. As we’ll see, they begin with no more “intelligence” than random guessing. Our goal is to iteratively adjust the network’s Weights and Biases to make it smarter. This is called training and we do it in two steps: Forward Propagation and Back Propagation.\n\nForward Propagation\nThink of this step as showing the Neural Network some input, and asking it to classify it. At the beginning, it’s very likely to get it wrong. But, like humans, we need to get things wrong before we know how to get them right. In Forward Propagation, we simply push all our features (pixels) through the Neural Network and ask, “what did you see?” The output is all the answers to that question.\n\n\nBack Propagation\nThink of this step as showing the Neural Network how right or wrong its answers were. We take all its answers to, “what did you see?” and come up with a measure of how wrong it was. We assign a numeric value to the “how wrong was it?” question with a cost function. From that numerica value, we can work backwards on all the neurons (nodes) to tell them, “you were X wrong, and this specific neuron contributed to Y amount of that error; adjust this neuron’s Weights and Biases by Z amount and try again.”\n3Blue1Brown has another excellent video on the conecepts of Back Propagation: “What is backpropagation really doing?” It’s got some great visuals to show how Forward Propagation pushes data forward through the Neural Network, and how Back Propagation pushes error measures backwards thrrough the Neural Network.\n\n\nTraining\nAnd that’s it! Our Neural Network learns by repeatedly making guesses, seeing how wrong it was, and adjusting its Weights and Biases. We repeat this over and over until it is good at the task! This is a lot like how people learn. Show a small child pictures of various farm animals over and over and ask them to name the animals. At first they’re very bad at it, but over time they get very good at it. There’s a lot of research out there that our artifical Neural Network is structured and operates like human brain neurons.\n\n\n\nGradient Descent\nGradient Descent is the most math-y piece of all this. Again, 3Blue1Brown has a great video: “Gradient descent, how neural networks learn”. This is the piece that is the most choose-your-own-adventure for how much you want to actually understand. I recommend diving in at least a little bit.\nImagine being at a point graph and you want to find which step to take to get to the minimum value. If you’ve taken any calculus before, you know that you can take the slope at the current point to tell you which way the graph is trending, and by how much. If you do this over and over, with small steps, you will approach a local minimum. That’s a 1-dimensional gradient descent. Our plan is to work with lots of repeated steps to get to a minumum of our cost function — the function telling us how bad our predictions are.\n\n\n\n\n\n\n\n\nReducing Loss: Gradient Descent, CC BY 4.0, via Google Developers\n\n\n\nYou can do this in two and three domensions as well. In fact, you can do it in as many dimensions as you need, which is very handy, because image classification has lots of dimensions. Imagine a color image. Its obvious dimensions are the pixel’s X value, Y value, Red value, Green value, Blue value, alpha value, and probably many more.\nQuick aside: a “tensor” is just a matrix with a high-order of dimensions.\n\n\n\n\n\n\n\n\nCC0 1.0 Universal (CC0 1.0) Public Domain Dedication, via Wikimedia Commons\n\n\n\nUltimately, we keep moving downward in our many-dimensional cost function to find a minimum value. The lower the cost, the better the prediction.\n\n\n\nEnvironment Setup\nAs stated, we’re going to build and train a fully functioning Neural Network using only NumPy. That said, I’m also going to install matplotlib just so that we can visualize some of the work as we go. It’s completely unnecessary to use matplotlib.\nIt’s also worth pointing out that I’m developing this in Python 3.10. Other versions of Python 3 probably work, too.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nOur Data\nAs mentioned, we’re going to be working with the MNIST database of handwritten digits. This is a very handy beginner’s data set because it’s done a lot of the upfront work for us. First of all, the data is normalized: all images are 28 x 28 and grayscale. The standard size is particularly helpful because we’re going to need that to set up the input layer of our Neural Network. In other situations, you’d have to crop or squash or letterbox your images to make them a standard size. This is mostly boilerplate, but some details of the file format that you may wish to know:\n\nThe images are encoded in the IDX file format, which looks for the presence of some magic numbers\nThere’s a documented structure to this data set, but that website is often behind HTTP basic auth because people like to script against it; here’s a Google cache\nThe images are gzip’d\nThe pixel values are 0 - 255, but we’re going to divide them into floats 0 - 1\n\nHere, we read in all the training data. We want to structure it into a matrix where each pixel is a row (this will line up with our input layer), and each image is a column. This gives us a matrix with 784 rows (28 x 28) and 60,000 columns.\nThis is the least intersting bit of code in the entire post.\n\nimport gzip\n\nDATA_DIR = './data/'\nTEST_IMAGE_FILE_PATH = f'{DATA_DIR}/t10k-images-idx3-ubyte.gz'\nTEST_LABEL_FILE_PATH = f'{DATA_DIR}/t10k-labels-idx1-ubyte.gz'\nTRAINING_IMAGE_FILE_PATH = f'{DATA_DIR}/train-images-idx3-ubyte.gz'\nTRAINING_LABEL_FILE_PATH = f'{DATA_DIR}/train-labels-idx1-ubyte.gz'\n\ndef load_images_and_labels(image_file_path, label_file_path):\n    labels = None\n    image_data = None\n\n    with gzip.open(label_file_path, 'r') as label_file:\n        # Verify magic number\n        magic_number_bytes = label_file.read(4)\n        magic_number = int.from_bytes(magic_number_bytes, byteorder='big', signed=False)\n        assert magic_number == 2049\n\n        # Read header telling us the number of labels\n        number_of_labels_bytes = label_file.read(4)\n        number_of_labels = int.from_bytes(\n            number_of_labels_bytes, byteorder='big', signed=False\n        )\n\n        buffer = label_file.read(number_of_labels)\n        labels = np.frombuffer(buffer, dtype=np.uint8)\n\n        with gzip.open(image_file_path, 'r') as image_file:\n            # Verify magic number\n            magic_number_bytes = image_file.read(4)\n            magic_number = int.from_bytes(\n                magic_number_bytes, byteorder='big', signed=False\n            )\n            assert magic_number == 2051\n\n            # Read header telling us the number of images\n            # And check that it matches the number of labels\n            number_of_images_bytes = image_file.read(4)\n            number_of_images = int.from_bytes(\n                number_of_images_bytes, byteorder='big', signed=False\n            )\n            assert number_of_images == number_of_labels\n\n            # Read the image height header\n            image_height_bytes = image_file.read(4)\n            image_height = int.from_bytes(\n                image_height_bytes, byteorder='big', signed=False\n            )\n\n            # Read the image width header\n            image_width_bytes = image_file.read(4)\n            image_width = int.from_bytes(\n                image_width_bytes, byteorder='big', signed=False\n            )\n\n            # read in the image data\n            buffer = image_file.read(image_width * image_height * number_of_images)\n            image_data = np.frombuffer(buffer, dtype=np.uint8).astype(np.float64) / 255\n\n            # Reshape it to a matrix such that each column is the pixels of the image\n            # So, we end up with a matrix with `image_width*image_height` rows and `number_of_images` colums\n            image_data = image_data.reshape(\n                number_of_images, image_width * image_height\n            ).T\n\n    return image_data, labels\n\nAnd show the first image and label:\n\ntraining_image_data, training_labels = load_images_and_labels(TRAINING_IMAGE_FILE_PATH, TRAINING_LABEL_FILE_PATH)\nfirst_image_data = training_image_data[:, 0].reshape((28, 28))  # All the rows in the first column, reshaped back to 28 x 28\nfirst_image_label = training_labels[0]\n\nprint(f'Label: {first_image_label}')\nplt.imshow(first_image_data, cmap='gray_r', vmin=0, vmax=1)\nplt.show()\n\nLabel: 5\n\n\n\n\n\n\n\n\n\n\n\nAn Untrained Neural Network\n\nInitializing Weights and Biases\nThe first step in creating our Neural Network is to build out Forward Propagation. Since our Neural Network will have an input layer, one hidden layer, and an output layer, we’ll need: * A set of Weights and Biases on the input layer * An Activation Function on the input layer * A set of Weights and Biases on the hidden layer * An Activation Function on the hidden layer\nAs mentioned, the Weights and Biases are variable and are determined in the model’s training process. But our model needs to start somewhere. There are a variety of strategies for initializing Weights and Biases. You could initialize to random values, but we’re going to use the He method to initialize random Weights, and the common recommendation of Biases initialized to zero.\n\n# weights_1 is the matrix of Weights between our input nodes and the first hidden layer\n# it has the shape num_labels x image_size\n#\n# biases_1 is the matrix of Biases between our input nodes and the first hidden layer\n# it has the shape num_labels x 1\n#\n# weights_2 is the matrix of Weights between our hidden layer and our output layer\n# it has the shape num_labels x num_labels\n#\n# biases_2 is the matrix of biases between our hidden layer and our output layer\n# it has the shape num_labels x 1\ndef init_params(input_layer_size, hidden_layer_size, output_layer_size):\n    weights_1 = np.random.randn(\n        hidden_layer_size,\n        input_layer_size,\n    ) * np.sqrt(2 / input_layer_size)\n    \n    weights_2 = np.random.randn(\n        hidden_layer_size,\n        output_layer_size,\n    ) * np.sqrt(2 / hidden_layer_size)\n\n    biases_1 = np.zeros((hidden_layer_size, 1))\n    biases_2 = np.zeros((output_layer_size, 1))\n\n    return weights_1, biases_1, weights_2, biases_2\n\n\n\nInput Layer Activation Function\nNext we need to select an activation function on our input layer. Common options are sigmoid and ReLU. ReLU is very effective and is a very common choice in computer vision models. Also, it’s incredibly simple to implement, so we’ll go with that.\nAll it does is take a value as input, and if the value is less than 0, return 0; if the value is greater than 0, return that value. That’s it! Here’s a handy post comparing ReLU to other activation functions.\n\ndef relu(value):\n    return np.maximum(value, 0)\n\n\n\nHidden Layer Activation Function\nThe last piece we need for our Forward Propagation is an Activation Function on the hidden layer. Remember: this Activation Function is feeding to our output layer, so we need something that generates ten prediction values. A good way to do this is to take our unactivated hidden layer and normalize it such that it outputs “prediction odds” to our output layer. Put another way, if the model is 91% sure an input is the number 5, it should activate the 5’s output node to 0.91, and the sum of all the other predictions should come to 0.09.\nWhat we’ve just described is called the Softmax function. The mast might look a little strange (here’s a good explainer), but all it’s doing is taking in a set of numbers and normalizing them to be 0 - 1, with a sum of 1.\n\ndef softmax(inputs):\n    exponentiated = np.exp(inputs)\n    probabilities = exponentiated / np.sum(exponentiated, axis=0)\n    return probabilities\n\n\n\nForward Propagation\nWe can now combine our initialized Weights and Biases and our Activation Functions to define Forward Propagation. You’ll notice some matrix math in here. Since our features (pixels) are arranged in a matrix, this is much more efficient that piping every pixel through functions one at a time. This becomes particularly true when you’re working with Neural Networks of higher dimensions. Here’s a refresher on matrix dot product. But you can basically think of it as multiplying the neurons in a layer by their weights.\n\ndef forward_prop(weights_1, biases_1, weights_2, biases_2, input_layer):\n    # First, calculate the unactivated values of the neurons in the first hidden layer\n    # Dot product weights_1 on input_layer, and then add biases_1\n    unactivated_hidden_layer = weights_1.dot(input_layer) + biases_1\n    # Then apply the ReLU activation function, to get our first hidden layer\n    activated_hidden_layer = relu(unactivated_hidden_layer)\n\n    # Next calculate the unactivated values of the neurons in the output layer\n    # Dot product weights_2 on activated_hidden_layer, and then add biases_2\n    unactivated_output_layer = weights_2.dot(activated_hidden_layer) + biases_2\n    # Then apply the softmax activation function, to get our activated output layer\n    output_layer = softmax(unactivated_output_layer)\n\n    return unactivated_hidden_layer, activated_hidden_layer, unactivated_output_layer, output_layer\n\nThis is actually all we need to do to have our model make a prediction. If we pass in a matrix of images, it’ll give an output_layer of predicted labels. But remember, we haven’t actually trained it yet, so it’ll make very bad predictions. The two types of variables we have, the Weights and Biases, are set to random values. So this thing is going to perform with roughly 10% accuracy (randomly picking one of our ten digits). Let’s see that.\nWe can define a measure of accuracy by dividing the number of correct predictions (the labels with the highest value in output_layer) by total number of predictions.\n\ndef get_predictions(output_layer):\n    return np.argmax(output_layer, 0)  # return the index of the max value prediction\n\n\ndef get_accuracy(predictions, labels):\n    return np.sum(predictions == labels) / labels.size\n\nHere’s what we get:\n\n# Set up our Neural Network shape\nimage_size = training_image_data.shape[0]\nnum_labels = len(np.unique(training_labels))\nhidden_layer_size = num_labels\n\n# Initialize our Weights and Biases\nweights_1, biases_1, weights_2, biases_2 = init_params(image_size, hidden_layer_size, num_labels)\n\n( \n    unactivated_hidden_layer,\n    activated_hidden_layer,\n    unactivated_output_layer,\n    output_layer,\n) = forward_prop(\n    weights_1,\n    biases_1,\n    weights_2,\n    biases_2,\n    training_image_data,\n)\n\npredictions = get_predictions(output_layer)\naccuracy = get_accuracy(predictions, training_labels)\n\nprint(f'Accuracy: {accuracy*100:.2f}%')\n\nAccuracy: 8.22%\n\n\n\n\n\nTraining the Neural Network\nNow that we have a stupid Neural Network, let’s train it so it can become a smart Neural Network. As mentioned before, Back Propagation is the proces in which we take the predictions from Forward Propagation, measure the error, and adjust our Weights and Biases through Gradient Descent.\nBefore we begin, we need one more helper function. We want to compare our known labels to all our predictions, and we can do that with a matrix with values of 1 (100%) at the correct index and 0 (0%) at all the incorrect indexes. We do this with One-hot encoding.\n\ndef one_hot(num_labels, labels):\n    # Create a matrix of all zeroes with shape num_images x num_labels\n    one_hot_y = np.zeros((labels.size, num_labels))\n    # For every image row, set Y'th (actual label) column to 1\n    # So, if the first row has label 5, set the 5th column to 1\n    one_hot_y[np.arange(labels.size), labels] = 1\n    # Return the Transposed matrix, so in the above example, the 5th row first column is 1\n    return one_hot_y.T\n\n\none_hot_output = one_hot(num_labels, training_labels)\n\n\nBack Propagation\nThis is where we actually do our Gradient Descent. It contains a little bit of calculus, and I highly adivse you pause here and watch these three videos: * What is backpropagation really doing? * Backpropagation Calculus * Backpropagation for Softmax and Multi-Class Classification | Complete Mathematical Derivation\nIt’s actually not all that imporant to master the calculus in these videos, but it’s very helpful to see what math is happening. From a high-level: we take the derivatives of our activation functions, and we reverse our matrix multiplication. It’s actually not too daunting. In the end, it gives is a measurement of error, and we use that error to adjust our Weights and Biases.\nSpeaking of derivatives, we’re gonna need the derivated of our ReLU Activation Function:\n\n# rectified_linear_unit only ever has a slope of 0 (negative X), or 1 (positive X)\ndef derivative_rectified_linear_unit(Z):\n    return Z &gt; 0\n\nAnd now we just go backwards through the Neural Network:\n\ndef back_prop(unactivated_hidden_layer, activated_hidden_layer, weights_2, output_layer, one_hot_output, training_image_data):\n    num_images = one_hot_output.size\n\n    # The difference between the predictions and the actual labels\n    d_predictions = output_layer - one_hot_output\n\n    # Take that d_predictions and cary back to the activated hidden layer\n    # And then average over all the neurons\n    d_weights_2 = (1 / num_images) * d_predictions.dot(activated_hidden_layer.T)\n\n    # Derivative of biases_ 2 is acutally just an average of the abosolute error\n    d_biases_2 = (1 / num_images) * np.sum(d_predictions)\n\n    # Derivative of unactived hidden layer\n    # Transpose the 2nd layer weights and dot on the known d_predictions\n    # And multiply that by the derivative of the activation function\n    d_hidden_layer = weights_2.T.dot(d_predictions) * derivative_rectified_linear_unit(unactivated_hidden_layer)\n\n    # Again, take our current derivative and cary it back to the input layer\n    # And average it over all the neurons\n    d_weights_1 = (1 / num_images) * d_hidden_layer.dot(training_image_data.T)\n    \n    # Derivative of biases_1 is like biases_2, but it's a simple average of the abolute error from the hiddle layer\n    d_biases_1 = (1 / num_images) * np.sum(d_hidden_layer)\n\n    return d_weights_1, d_biases_1, d_weights_2, d_biases_2\n\n\n\n\nTraining Our Model\n\nLearning Rate\nWe’re almost ready to train our model. The last piece here is to actually update our Weights and Biases after Back Propagation. You may be tempted to simply subracts the differences returned by back_prop but it’s not quite so simple. Remember, our Gradient Descent is good at telling us the slope at our current location, but it’s very unlikely to be a straight line. Instead, we’re going to want to take smaller steps so that we don’t over-shoot.\nWe need to introduce a variable called learning_rate, sometimes called alpha. This is a hyperparameter, which simply means that our model can’t learn the correct value through training; we have to set it ourselves. There are techniques to make this process more efficient, but usually it’s a bit of guess and check. If your model has a very bad time improving, you should try adjusting your learning rate. Common learning rates are between 0.01 and 1. If you’d like to read more about picking a learning rate, this is a good post.\nThrough some trial and error, I found that a learning rate of 0.5 worked pretty well for this model.\n\nlearning_rate = 0.5\n\nWe can use this to update our Weights and Biases:\n\ndef update_params(weights_1, biases_1, weights_2, biases_2, d_weights_1, d_biases_1, d_weights_2, d_biases_2, learning_rate):\n    weights_1 = weights_1 - learning_rate * d_weights_1\n    biases_1 = biases_1 - learning_rate * d_biases_1\n    weights_2 = weights_2 - learning_rate * d_weights_2\n    biases_2 = biases_2 - learning_rate * d_biases_2\n\n    return weights_1, biases_1, weights_2, biases_2\n\n\n\nTraining\nNow let’s train our model! You might recall that it’ll take many iterations of Forward Propagation and Back Propagation for our model to get smart. But how many iterations? I don’t actually know! Let’s decide right now that we want our model to be at least 90% accurate on the training data. We’ve already got a function to tell us accuracy, so let’s let it train until that reaches 90%.\nThis is the slow part, and the part that often benefits from GPUs. But, as you’ll see, this Neural Network trains surpisingly quickly! On my laptop with no GPU and a 2.6 GHz 6-Core Intel Core i7, the model rechease 90% accuracy on the training data in under two minutes!\n\nimage_size = training_image_data.shape[0]\nnum_labels = len(np.unique(training_labels))\nhidden_layer_size = num_labels\n\nweights_1, biases_1, weights_2, biases_2 = init_params(image_size, hidden_layer_size, num_labels)\n\naccuracy = 0\niteration = 0\naccuracy_measurements = [0]  # A running list of our accuracy for each iteration\n\nwhile accuracy &lt; 0.9:\n    iteration += 1\n\n    ( \n        unactivated_hidden_layer,\n        activated_hidden_layer,\n        unactivated_output_layer,\n        output_layer,\n    ) = forward_prop(\n        weights_1,\n        biases_1,\n        weights_2,\n        biases_2,\n        training_image_data,\n    )\n\n    one_hot_output = one_hot(num_labels, training_labels)\n\n    (\n        d_weights_1,\n        d_biases_1,\n        d_weights_2,\n        d_biases_2,\n    ) = back_prop(\n        unactivated_hidden_layer,\n        activated_hidden_layer,\n        weights_2, output_layer,\n        one_hot_output,\n        training_image_data,\n    )\n\n    (\n        weights_1,\n        biases_1,\n        weights_2,\n        biases_2,\n    ) = update_params(\n        weights_1,\n        biases_1,\n        weights_2,\n        biases_2,\n        d_weights_1,\n        d_biases_1,\n        d_weights_2,\n        d_biases_2,\n        learning_rate,\n    )\n\n    predictions = get_predictions(output_layer)\n    accuracy = get_accuracy(predictions, training_labels)\n\n    accuracy_measurements.append(accuracy)\n\n    # Print out upadtes as we go\n    if iteration == 1 or iteration % 100 == 0:  \n        print(f'Iteration: {iteration} | Accuracy: {accuracy*100:.2f}%')\n\nprint(f'Achieved {accuracy*100:.2f}% accuracy after {iteration} iterations!')\n\n# Plot the accuracy curve\nplt.plot(accuracy_measurements)\nplt.xlabel('Iteration')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)\nplt.show()\n\nIteration: 1 | Accuracy: 9.41%\nIteration: 100 | Accuracy: 72.68%\nIteration: 200 | Accuracy: 82.50%\nIteration: 300 | Accuracy: 85.56%\nIteration: 400 | Accuracy: 87.01%\nIteration: 500 | Accuracy: 87.85%\nIteration: 600 | Accuracy: 88.51%\nIteration: 700 | Accuracy: 88.97%\nIteration: 800 | Accuracy: 89.37%\nIteration: 900 | Accuracy: 89.66%\nIteration: 1000 | Accuracy: 89.90%\nAchieved 90.00% accuracy after 1037 iterations!\n\n\n\n\n\n\n\n\n\nNow we have the Weights and Biases for our Neural Network to achieve 90% accuracy against our training data. That’s pretty cool, but the real test to to run images through the model that it’s never seen before. If we overfit the model, it might only be good at recognizing the images it was trained on (kindof like cramming for a test and memorizing the answers without actually learning anything). Let’s run it against our 10,000 test images. At this point we only need to run it through forward_prop because we’re no longer training. This is very fast!\n\ntest_image_data, test_labels = load_images_and_labels(TEST_IMAGE_FILE_PATH, TEST_LABEL_FILE_PATH)\n_, _, _, test_output_layer = forward_prop(\n        weights_1,\n        biases_1,\n        weights_2,\n        biases_2,\n        test_image_data,\n    )\ntest_predictions = get_predictions(test_output_layer)\ntest_accuracy = get_accuracy(test_predictions, test_labels)\nprint(f'Test Data Set Accuracy: {test_accuracy*100:.2f}%')\n\nTest Data Set Accuracy: 90.32%\n\n\nThat’s great! And let’s look at a sample of 10 test images and how they were labeled:\n\nfig, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 4))\n\nfor ax in axes.flat:\n    random_index = np.random.randint(0, len(test_labels))\n    random_test_image_data = test_image_data[:, random_index].reshape((28, 28))\n    random_test_image_label = test_labels[random_index]\n    random_prediction = test_predictions[random_index]\n\n    ax.imshow(random_test_image_data, cmap='gray_r', vmin=0, vmax=1)\n    ax.set(title=f'Actual: {random_test_image_label}\\nPredicted: {random_prediction}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nVery impressive!\nWe’ve successfully built a computer vision Machine Learning model using nothing but NumPy. Hopefully this demystified some of the some of the concepts of Neural Networks!\n\n\n\nAcknowledgements\nMy first pass at tackling this topic began with Samson Zhang’s “Building a neural network FROM SCRATCH (no Tensorflow/Pytorch, just numpy & math)”. This post looks a lot like his work, though I hit a number of implementation errors while following along. After digging into the articles and videos linked in this post, I made a number of adjustments to the model’s training to get to this final output.\n\n\nLicense\nCopyright (c) 2023, Matt Hodges\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of Building a Neural Network From Scratch with NumPy nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "posts/2024-07-20-amused-entirely-to-death/index.html",
    "href": "posts/2024-07-20-amused-entirely-to-death/index.html",
    "title": "Amused Entirely To Death",
    "section": "",
    "text": "At this point there’s nothing novel in pointing out that news and politics has devolved into an entertainment competition. But I can’t become so numb to let last week’s Republican National Convention go without comment.\nI won’t get into detailed summaries or link to videos. The Republican National Convention, unsurprisingly, was rife with jingoism, xenophobia, and hate. But what stood out was a primetime performance on the final night:\n\n\n\nHulk Hogan ripping his shirt off during the 2024 Republican National Convention\n\n\nIf you missed the social media frenzy, the short version is Hulk Hogan took the stage during a primetime speech to say, among many pernicious things:\n\nBut what happened last week, when they took a shot at my hero, and they tried to kill the next president of the United States, enough was enough! And I said, ‘Let Trump-A-Mania run wild brother! Let Trump-A-Mania rule again!’\n\nAnd then he ripped off his shirt and the stadium of suited leaders of the Republican party lost their minds in cheers and applause. Never mind that pundits and Republican leaders assured us that — after the attempted assassination of Donald Trump days prior — this convention would be a message of national unity. Never mind whoever the they are that he’s talking about. Hulk Hogan gave the people what they wanted: a viral-worthy performance that makes you feel something when you press share.\nThis moment exemplified a broader issue that has been gradually intensifying. The disgraced former president, after all, is a reality TV character, epitomizing the entertainment-driven nature of modern politics. To note that is not to minimize the harm he has inflicted and will inflict if given another chance. But it’s an apt time to highlight a recurring misdiagnosis of modern Conservative power.\n\nOur Misdiagnosis of Conservative Power\nAs astute online big-brains, we’re frequently high-fiving ourselves for naming the Right’s methods and tactics as Orwellian (despite the fact that most people haven’t actually read Nineteen Eighty-Four). We get those small hits of dopamine by labeling our eroding rights as such. But by and large, power-building of the Trump era isn’t Orwellian at all. Just as Donald Trump himself isn’t Machiavellian at all (a core tenet from The Prince is a firm warning against flatterers — Donald Trump could never). Yes, the Right does deploy assaults that could be lifted directly from Orwell or Bradbury — look no further than the book-banning crusades or the “do not believe what you see” lies from the press briefing rooms. But when evaluating how we got here and why we’re stuck here, it’s instructive to look to Neil Postman’s observations in Amusing Ourselves to Death:\n\nBut we had forgotten that alongside Orwell’s dark vision, there was another - slightly older, slightly less well known, equally chilling: Aldous Huxley’s Brave New World. Contrary to common belief even among the educated, Huxley and Orwell did not prophesy the same thing. Orwell warns that we will be overcome by an externally imposed oppression. But in Huxley’s vision, no Big Brother is required to deprive people of their autonomy, maturity and history. As he saw it, people will come to love their oppression, to adore the technologies that undo their capacities to think. What Orwell feared were those who would ban books. What Huxley feared was that there would be no reason to ban a book, for there would be no one who wanted to read one. Orwell feared those who would deprive us of information. Huxley feared those who would give us so much that we would be reduced to passivity and egoism. Orwell feared that the truth would be concealed from us. Huxley feared the truth would be drowned in a sea of irrelevance. Orwell feared we would become a captive culture. Huxley feared we would become a trivial culture, preoccupied with some equivalent of the feelies, the orgy porgy, and the centrifugal bumblepuppy. As Huxley remarked in Brave New World Revisited, the civil libertarians and rationalists who are ever on the alert to oppose tyranny “failed to take into account man’s almost infinite appetite for distractions.” In 1984, Orwell added, people are controlled by inflicting pain. In Brave New World, they are controlled by inflicting pleasure. In short, Orwell feared that what we fear will ruin us. Huxley feared that what we desire will ruin us.\n\nI’m not particularly interested in arguing that “we’re living in a dystopia, actually”. Despite our collective addiction to devices that incessantly tell us that the world is terrible, I still believe things are getting better over time. And I largely reject the, “no one has had it as bad as we have it” notions from my generational cohort. But we can only pursue the long arc of progress if we continue to care enough to do so. If I was architecting a #resist movement of 2024, it would be to resist the trivialization of political power.\nIt’s important to reflect on Huxley’s and Postman’s ideas, even if it makes us uncomfortable. So many people today claim they’ve stopped consuming news altogether, but often they simply switch to more entertaining sources that don’t feel like homework. Consider this: how many of your friends can name a single Supreme Court justice without hints? You should start asking! This exercise, which I’ve conducted socially, reveals fascinating results! These observations aren’t about intelligence — they’re about priorities.\nAgain, I don’t think I’m pointing out anything novel here. Pundits analyze political events in terms of “energy” and base success on Nielsen viewership metrics. Matt Gaetz and Ted Cruz both have side gigs as podcast hosts. Marjorie Taylor Greene dresses up as Cruella de Vil to scream during the Statue of the Union.\n\n\n\nMarjorie Taylor Greene dressed up as Cruella de Vil to scream during the Statue of the Union\n\n\nIt’s all incredibly stupid. And it’s helpful to have an appropriate label for what’s been happening for a long time.\nSo, when Hulk Hogan took to the stage to frivolously transport the Right’s power-holders back to the 1980s while ripping off his shirt, exalting “Trump-A-Mania” (aptly named), it couldn’t be more clear that ambient Conservative power-building is Huxleyan, not Orwellian. We are amusing ourselves entirely to death.\nSeems bad."
  },
  {
    "objectID": "posts/2024-07-30-austin-hot-or-not/index.html",
    "href": "posts/2024-07-30-austin-hot-or-not/index.html",
    "title": "Austin, Texas: Hot or Not?",
    "section": "",
    "text": "I live in Austin, Texas. And last summer I felt like:\n\nBut this year, I’ve felt more like:\n\nAnd earlier today I thought aloud to the group chat:\n\nI need to look up if Austin is being weird this year. Last year we got to like 50 consecutive days over 100. I don’t think we’ve cracked 100 yet this year? Is there a website that answers this question?\n\nLast year the heat was so bad that local news outlets were keeping a running tally of how many consecutive days we broke 100°F. It turns out we had 45 straight days of triple-digit heat in 2023, which began on July 8 and continued through August 22. I’m writing this on July 30, 2024 and I can’t recall a single day above 100°F yet this year.\nYear-vs-year location based time series temperature data absolutely seems like a thing that should exist. Every month or so someone posts the updated doom surface air temperature graph, so surely I can just look that data up for my location, right?\nOn weather.gov you can get your own version of this graph. Pretty cool! But only for the current year:\n\nYou can also get tabular historic data within monthly windows that sometimes come as html and sometimes come as PDF. Also cool. But not convenient:\n\nAfter about 15 minutes of clicking, I couldn’t find a great way to generate the viz I was looking for; and I couldn’t get an easy data export. Maybe there’s a one-click way to get CSVs, but I didn’t find it. But after about 5 more minutes of googling, I did find the National Oceanic and Atmostpheric Administration’s Climate Data Online portal, which has an API.\n\nNCDC’s Climate Data Online (CDO) offers web services that provide access to current data. This API is for developers looking to create their own scripts or programs that use the CDO database of weather and climate data.\n\nHey, that sounds like me!\nThe API needs an access token. Wonderfully, all I needed to do was type in my email address and roughly one second later an access token landed in my inbox. LFG.\nFrom here it took a bit more reading to grok what data is available and in what formats, but I eventually found out about GHCND, or the Global Historical Climatology Network daily:\n\nThe Global Historical Climatology Network daily (GHCNd) is an integrated database of daily climate summaries from land surface stations across the globe. GHCNd is made up of daily climate records from numerous sources that have been integrated and subjected to a common suite of quality assurance reviews.\n\nThat sounds like it might contain what I’m looking for.\nNext, there are a lot of ways to filter this data by location, but stationid caught my attention. I found this list of GHCND stations and decided to go with AUSTIN BERGSTROM INTL AP because it’s the same location from the tabular data above. It has the identifier USW00013904.\nAfter a quick pip install requests pandas matplotlib and tossing my token into a NCDC_CDO_TOKEN environment variable, we’re ready to jam.\nFirst let’s get a function to grab some data. I’m intersted in comparing year over year, so let’s grab a year at a time.\n\nimport os\n\nimport matplotlib.patches as mpatches\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport requests\n\ndef get_max_temps(year, limit=366):\n    token = os.getenv(\"NCDC_CDO_TOKEN\")\n    start_date = f\"{year}-01-01\"\n    end_date = f\"{year}-12-31\"\n    url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n    params = {\n        \"datasetid\": \"GHCND\",\n        \"stationid\": \"GHCND:USW00013904\",\n        \"startdate\": start_date,\n        \"enddate\": end_date,\n        \"datatypeid\": \"TMAX\",  # max temp\n        \"units\": \"standard\",  # 🇺🇸\n        \"limit\": limit,  \n    }\n    headers = {\n        \"token\": token  \n    }\n\n    response = requests.get(url, headers=headers, params=params)\n    data = response.json()\n    return data\n\nLet’s look at the first three:\nget_max_temps(2024, limit=3)\n{\n    \"metadata\": {\n        \"resultset\": {\n            \"offset\": 1,\n            \"count\": 209,\n            \"limit\": 3\n        }\n    },\n    \"results\": [\n        {\n            \"date\": \"2024-01-01T00:00:00\",\n            \"datatype\": \"TMAX\",\n            \"station\": \"GHCND:USW00013904\",\n            \"attributes\": \",,W,2400\",\n            \"value\": 58.0\n        },\n        {\n            \"date\": \"2024-01-02T00:00:00\",\n            \"datatype\": \"TMAX\",\n            \"station\": \"GHCND:USW00013904\",\n            \"attributes\": \",,W,2400\",\n            \"value\": 53.0\n        },\n        {\n            \"date\": \"2024-01-03T00:00:00\",\n            \"datatype\": \"TMAX\",\n            \"station\": \"GHCND:USW00013904\",\n            \"attributes\": \",,W,2400\",\n            \"value\": 51.0\n        }\n    ]\n}\nGreat! We can pull from the date and the value fields. Let’s grab all of 2024 and shove it into a DataFrame.\n\ndef to_df(data):\n    # Extract date and truncate off the time part\n    dates = [item[\"date\"][:10] for item in data[\"results\"]]\n\n    # Grab the max temp value for each date\n    max_temps = [item[\"value\"] for item in data[\"results\"]]\n\n    # Create a DataFrame\n    df = pd.DataFrame({\"date\": dates,\"max_temp\": max_temps})\n\n    # Set the `date` col as a datetime and make it the index\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    df.set_index(\"date\", inplace=True)\n    \n    return df\n\nQuick spot check:\n\ndf_2024 = to_df(get_max_temps(2024))\n\nprint(f\"Head:\\n{df_2024.head()}\")\nprint(f\"Tail:\\n{df_2024.tail()}\")\nprint(f\"Format:\\n{df_2024.dtypes}\")\n\nHead:\n            max_temp\ndate                \n2024-01-01      58.0\n2024-01-02      53.0\n2024-01-03      51.0\n2024-01-04      58.0\n2024-01-05      67.0\nTail:\n            max_temp\ndate                \n2024-07-23      82.0\n2024-07-24      89.0\n2024-07-25      88.0\n2024-07-26      89.0\n2024-07-27      86.0\nFormat:\nmax_temp    float64\ndtype: object\n\n\nAwesome. I’m writing this on 2024-07-30 and it’s got data up through 2024-07-27. Good enough for me!\nNow to actually get at what I was trying to do this whole time. I’m going to grab DataFrames for 2023 and 2024, and plot a time series of each.\n\ndf_2023 = to_df(get_max_temps(2023))\n\n# Adjust 2023 dates to match the 2024 index\n# This is how we shift the graph to overlap\n# If you don't do this, 2024 comes after, not on top of, 2023\ndf_2023.index = df_2023.index.map(lambda x: x.replace(year=2024))\n\n# Plot the data\nfig, ax = plt.subplots(figsize=(10, 6))\ndf_2023.plot(ax=ax, color=\"black\", legend=\"2023\")\ndf_2024.plot(ax=ax, color=\"red\", legend=\"2024\")\n\n# Sett x-axis to display month labels\nax.set_xticks(\n    pd.date_range(\n        start=df_2023.index.min(),\n        end=df_2023.index.max(),\n        freq='MS',\n    )\n)\nax.set_xticklabels(\n    pd.date_range(\n        start=df_2023.index.min(),\n        end=df_2023.index.max(),\n        freq='MS',\n    ).strftime('%B')\n)\n\n# Formatting\nblack_patch = mpatches.Patch(color=\"black\", label=\"2023\")\nred_patch = mpatches.Patch(color=\"red\", label=\"2024\")\nplt.legend(handles=[black_patch, red_patch])\nax.set_title(\"Max Daily Temperatures Recorded in the Austin-Bergstrom Airport Area\")\nplt.xticks(rotation=45)\n\nplt.show()\n\n\n\n\n\n\n\n\nSo that’s pretty cool. Most of 2024 has tracked 2023 for daily high temperatures. But not July. July has been weirdly cooler than last year. Or last year was weirdly hotter than normal.\nActually, let’s see if we can tease that out. Let’s grab the past 10 years.\n\nimport time\n\n# Create a dictionary of year:DataFrame\nyear_dfs = {}\nfor year in range(2014, 2024):\n    year_dfs[year] = to_df(get_max_temps(year))\n    # Be a nice internet citizen and wait between requests\n    time.sleep(5)\n\n# Adjust pre-2024 dates to match the 2024 index\n# This is how we shift the graph to overlap\n# If you don't do this, 2024 comes after, not on top of, 2023\nfor df in year_dfs.values():\n    df.index = df.index.map(lambda x: x.replace(year=2024))\n\n# Plot the data\nfig, ax = plt.subplots(figsize=(10, 6))\nfor year, df in year_dfs.items():\n    if year == 2023:\n         df.plot(ax=ax, label=\"2023\", color=\"gold\")\n    else:\n        df.plot(ax=ax, color=\"gray\")\ndf_2024.plot(ax=ax, label=\"2024\", color=\"red\")\n\n# Sett x-axis to display month labels\nax.set_xticks(\n    pd.date_range(\n        start=year_dfs[2023].index.min(),\n        end=year_dfs[2023].index.max(),\n        freq='MS'\n    )\n)\nax.set_xticklabels(\n    pd.date_range(\n        start=year_dfs[2023].index.min(),\n        end=year_dfs[2023].index.max(),\n        freq='MS',\n    ).strftime('%B')\n)\n\n# Formatting\nax.set_title(\n    \"Max Daily Temperatures Recorded in the Austin-Bergstrom Airport Area 2014 - 2024\"\n)\nplt.xticks(rotation=45)\ngold_patch = mpatches.Patch(color=\"gold\", label=\"2023\")\nred_patch = mpatches.Patch(color=\"red\", label=\"2024\")\nplt.legend(handles=[gold_patch, red_patch])\n\nplt.show()\n\n\n\n\n\n\n\n\nSeems like Austin’s 2023 summer was on the hotter side, and so far the 2024 summer is on the cooler side.\nAnd was I correct that we haven’t cracked 100 yet this year?\n\nprint(df_2024[df_2024[\"max_temp\"] &gt;= 100])\n\n            max_temp\ndate                \n2024-07-02     100.0\n2024-07-05     100.0\n\n\nComputers!"
  },
  {
    "objectID": "posts/2024-07-23-how-did-skannerz-work/index.html",
    "href": "posts/2024-07-23-how-did-skannerz-work/index.html",
    "title": "How Did Skannerz Work?",
    "section": "",
    "text": "This post is a redux from a now-deleted social media thread. It felt too important to let bit rot.\nIf you’re a Millennial of a certain age, or perhaps a Baby Boomer who raised Millennials,1 you might remember the 2001 toy Skannerz by Radica. It was a gotta-catch-em-all game that involved scanning real-world barcodes to collect monsters and objects, and to battle other Skannerz. It was a hand-held gadget toy back when consumer electronics were still weird and fun and we had more products than just iPhone. I had a blue one. It looked like this:\nThe toy/game had an A+ premise: alien monsters transported down to earth and decided to hide inside of the barcodes on products all around your home (or, more annoyingly to your parents, all around the grocery store). Your job was to scan every barcode you could get your hands on, fight and capture the alien monsters, and then fight the monsters your friends collected. And to make the weirdest Pokémon ripoff complete: the Skannerz came in three colors — red, blue, and green — that could only collect monsters of their associated “tribes”. This really good commercial explains:\nBecause I was already a major dork at 11 years old, I was intrigued by how the device worked. How did it go from barcode to monster? There was no way it was talking to a server (although I did imagine the world’s greatest PHPMyAdmin at the time). I guessed that it had every possible barcode referenced internally. But that’s not quite correct. It was a little more clever than that.\nBut frirst, a quick primer on barcodes. There are many variations; this is a UPC Version A — very common in the United States. It has a basic specification: that first digit way to the left is the product type (sometimes called a number system). The next five digits identify the manufacturer. The next five identify the product. And at the end is a checksum digit. The details of how to implement the spec aren’t all too important for our Skannerz exploration.\nOkay, back to the Skannerz game. As mentioned above, there were 3 different “tribes”, identified by which color scanning device you had. And there were 126 total monsters. So each tribe could capture 42 monsters. If you wanted to catch ’em all you needed to buy all three. Business!\nYou could also collect non-monster items from barcodes. And some barcodes healed your injured monsters. Again, these toys had no wireless communication (it was 2001!) so all of the logic for item or monster identification was baked right into the device. But how?\nThe Skannerz patent is conveniently revealing!2 The device only cares about the “product” section (denoted below as 1315). If the first digit is 0-5, you’ve scanned a monster. 6-9, you’ve scanned an item. Digits 3, 4, and 5 identify the item/monster.\nIf the first digit in the barcode’s product code is 0 - 5, we’re in Monster Mode.\nWe’ve got 1000 possible values (000-999 across digits 3, 4, and 5 in our product code) to identify 126 monsters. The patent goes on to explain how the magic of division solves this problem:\n\\[\n\\frac{1000}{126} = 7.94\n\\]\nAnd there was much rejoicing.\nThe range of numbers from 000 to 007 correspond to the first monster in Tribe 1, 008 to 015 correspond to the first monster in Tribe 2, and so on.\nThe patent then goes on to address the fact that 126 doesn’t divide well into 1000, and that 7.94 is not an integer. We only follow this eight-stepping until we get through the 124th monster, and then:\nNow, if the first digit in the barcode’s produt code is 6 - 9, we’re in Item Mode.\nSimilarly, there were 24 items in the game + 1 for healing. So 25 items. Again, we’ve got 1000 values to work with:\n\\[\n\\frac{1000}{25} = 40\n\\]\nSo a range of 40 numbers can be used to define each item. Item 1 corresponds to the range of numbers from 000 through 039, Item 2 corresponds to the range of numbers from 040 through 079, and so on. And great news: 40 is an integer.\nQuick aside: the UPC Version A codec above is the the only format outlined in the Skannerz patent. But the patent also burries this little nugget:\nWhat does that mean? It literally says nothing else about what invention is being claimed there, but good on the Radica lawyers for planting a flag I guess? Maybe the Skannerz Commander, which I never had, rolled its own encryption algorithm?\nBut that’s really it! If you knew this encoding scheme, and had access to a printer, you could collect all the monsters and items pretty quickly. Anyone else remember Barcode Mill? Of course people knew; there were unofficial barcode books you could buy to help you complete your collection. But where’s the fun in that?\nThanks for indulging my dork nostalgia. I look forward to the Greta Gerwig adaptation."
  },
  {
    "objectID": "posts/2024-07-23-how-did-skannerz-work/index.html#footnotes",
    "href": "posts/2024-07-23-how-did-skannerz-work/index.html#footnotes",
    "title": "How Did Skannerz Work?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGenerational cohort discourse is stupid.↩︎\nYou don’t need to be a lawyer to read a patent. They can be very interesting! This one had cartoon drawings!↩︎"
  },
  {
    "objectID": "posts/2022-07-17-exploring-lambda-calculus-python/index.html",
    "href": "posts/2022-07-17-exploring-lambda-calculus-python/index.html",
    "title": "Exploring the Lambda Calculus with Python",
    "section": "",
    "text": "This post is adapted from a Jupyter Notebook found on GitHub.\nThis post explores some basic ideas of the Lambda Calculus, and how to use it to implement a computation system with it. We will define numbers and operators from scratch, and use that to implement the square_sum function.\nIf you’re new to the Lambda Calculus, or functional programming in general, you may wish to start with some of these resources:\n\nDavid Beazley’s Lambda Calculus from the Ground Up - PyCon 2019\n\nIf you’re someone who learns well by watching and listening, I highly recommend that you watch this talk. A significant portion of the concepts below come from watching this talk more than once.\n\nBen Eater’s Making a computer Turing complete\nLambda Calculus | Wikipedia\nCurrying | Wikipedia\n\nThis post assumes you are fairly familiar with Python and Python’s lambda expressions.\n\nRules of Our System\nThe Lambda Calculus asserts that any computational system can be implemented with a set of three simple rules: * You can define variables * You can define single-argument functions * You can call single-argument functions\nThat’s it. No numbers. No operators. No control flow. No data structures.\nI find it fascinating that with these very minimal concepts, the Lambda Calculus asserts that we can create a fully functional computer! This is, of course, a very minimal explanation of the rules of the Lambda Calculus, and I invite you to consult the references above for more information and formal definitions!\n\n\nThe Challenge\nUsing the rules described above, we want to create a system that can calculate the square-sum of any inputs. Again, we only have single-argument functions. That means we have no integers, no addition, and no multiplication. We’re going to have to create those using nothing but single-argument functions that accept single-argument functions as input and can only return single-argument functions.\nFor reference, consider the square_sum function, that may be written in Python as:\n\ndef square_sum(a, b):\n    return (a*a) + (b*b)\n\n\nsquare_sum(5, 2)\n\n29\n\n\n\nCurrying\nAs previously mentioned, our computation system requires that we can only create functions and those functions must accept one and only one argument. This may seem like a limiting requirement, but let’s take a look at what we can do with the idea of Currying — a method for transforming multi-argument functions into a chain of single-argument functions. This allows us to re-write our Python implementation as:\n\ndef square_sum(a):\n    def inner(b):\n        return (a*a) + (b*b)\n    return inner\n\n\nsquare_sum(5)(2)\n\n29\n\n\nIn our curried version above, square_sum accepts the first argument, a and returns a function that accepts the second argument, b. We can then call that returned inner function to complete our calculation. Currying is a fundamental strategy for computation in the Lambda Calculus.\n\n\n\nOur Basic Building Block\nUnless you’re already familiary with the Lambda Calculus, or you’re a veteran of functional programming, you’re probaby very accustomed to computing by operating on state. You have data structures, or numbers, or bits, and you operate on them and then you persist new data structures, or numbers, or bits.\nOur concept of integers is a perfect example. As children, we learned that the concept of 3 can be represented by holding up three fingers on our hand, and seeing all three of them, and pointing to them. The Lambda Calculus asks us to adjust that concept away from state and towards behavior. Instead of holding up three fingers, what if we held up one finger three times. It may be harder for us see that idea of 3, but it is a representation of 3 nonetheless.\nSit with this idea of behavior representing integers, because behavior will be how we represent everything. And in our system, functions are behavior. Our function could be the act of holding up a finger, pressing a button, or anything else we need it to be.\nLet’s use that metaphor of pressing a button. The button press is our behavior, and behaviors are functions. And arguments are functions. And we can only return functions. So, let’s write that:\n\ndef button_press(f):\n    def g(x):\n        return f(x)\n    return g\n\nNot much to see here yet. In fact, our system isn’t designed to see anything. It’s designed to do computations within a given set of rules.\nWe’re designing a system of computation, and we can think about this system like instruction that run on a CPU. But we’re humans, and it’s helpful for us to be able to see the results of our computation in ways that we can understand. So, we’re going to introduce an external system that is not within the Lambda Calculus, but can interface with it. Think of this as a peripheral like a printer. It’s not used to do any of our computation. It can do special things that our CPU can’t do, and it’ll connect to our system as a function, because our system can only work with functions.\nLet’s pretend our system has a printer attached that can only print the * character. We’ll interface with it via an emit function.\nHere is our not-of-our-system emit function:\n\ndef emit(func):\n    def asterisk(x):\n        return f'{x}*'\n    return func(asterisk)('')\n\nThis is kindof strange. Our external emit function takes in some function and has an inner asterisk-generating function. Let’s hook it up to our button_press function:\n\nemit(button_press)\n\n'*'\n\n\nWhat just happened here? We call our emit function (external from our system) by passing in our button_press function (internal to our system). We did it one time, and it yielded a single *. Again, this is just a convenience interface so that we can see what’s going on, and isn’t necessary to do any of our actual computation.\n\n\nNumbers\nAbove we began to describe how functions, or behaviors, can represent numbers. A single call to button_press yielded some concept of 1. What if we didn’t think about it as one call to button_press anymore, but as the idea of one behavior:\n\ndef ONE(f):\n    def g(x):\n        return f(x)\n    return g\n\nemit(ONE)\n\n'*'\n\n\nIf you’ve made it this far, you’re probably thinking, “Hey, Python has a way to represent single-argument functions, and they’re called lambdas!” Let’s start using that instead of the expanded button_press function:\n\nONE = lambda f : lambda x : f(x)\n\nemit(ONE)\n\n'*'\n\n\nCool. So we know how to represent the concept of 1 using only single-argument functions. We can represent 2 by calling our function twice, because in our system numbers are behaviors:\n\nTWO = lambda f : lambda x: f(f(x))\n\nemit(TWO)\n\n'**'\n\n\nThis is all well and good, but we’re not really going to try to implement every single number are we? That wouldn’t make a very good computer. How can we represent all countable numbers?\nIf you look closely at our definitions above, ONE is a single call to f(), while TWO is f(f()). This means that if we’re at any given number, we can get to the next number by calling f() again. We can define an INCREMENT() function to do just that. I find it helpful to start by looking at this through the expanded Python functions first:\n\ndef ONE(f):  # f is the behavior we want to do\n    def g(x):  # x is the curried second argument\n        return f(x)\n    return g\n\n\ndef INCREMENT(n):  # n is the concept of the number we already have\n    def g(f):  # f is the behavior we want to do\n        def h(x):  # x is the curried second argument\n            return f(n(f)(x))  # we call f() again on our n(f)(x)\n        return h\n    return g\n\n\nemit(INCREMENT(ONE))\n\n'**'\n\n\nSpend some time stepping through the above code to understand it. We’re essentially wrapping nested functions as many times as we need to get to the next number. Once you’ve wrapped your head around it, see that we can re-write the above as lambdas:\n\nONE = lambda f : lambda x : f(x)\n\nINCREMENT = lambda n : lambda f : lambda x : f(n(f)(x))\n\nTWO = INCREMENT(ONE)  # our calculated TWO from ONE\n\nemit(TWO)\n\n'**'\n\n\nIf we can calculate TWO from ONE, we can calculate THREE:\n\nTHREE = INCREMENT(TWO)\n\nemit(THREE)\n\n'***'\n\n\nPretty neat! We can keep doing this to infinity, either by saving values, or calculating them on the fly! But you may be wondering, what about ZERO? Well, we’ve defined ONE as a single call to any behavior f(), so ZERO would simply be no calls to that behavior:\n\nZERO = lambda f : lambda x : x\n\nemit(ZERO)\n\n''\n\n\nSee how ZERO doesn’t call f() at all? What’s fun here is that we no longer need to have defined ONE, we can calculate it from ZERO!\n\nONE = INCREMENT(ZERO)\n\nemit(ONE)\n\n'*'\n\n\n\n\nOperators\nNow that we know we can represent numbers as function calls, let’s start working on math operators. We’ve already introduced one critical operator, INCREMENT, and we can use that to introduce others. Let’s start with ADD. Addition is can be thought of as incrementing M times on a number N. For example, 2 + 3 could be described as incrementing 2, three times. Before we attempt to implement that in our system, let’s look again to how we would Curry this in Python:\n\ndef add(a):\n    def inner(b):\n        return a + b\n    return inner\n\nadd(2)(3)\n\n5\n\n\n\ndef ADD(a):  # Our first number, which is always a function\n    def inner(b):  # Our second number, which is always a function\n        return b(INCREMENT)(a)  # Increment a, b times\n    return inner\n\n\nFIVE = ADD(TWO)(THREE)\nemit(FIVE)\n\n'*****'\n\n\nSince everything is always a function, our numbers can be used not only as representations of calculations, but also as executors. Here’s our ADD as a lambda:\n\nADD = lambda a : lambda b: b(INCREMENT)(a)\n\nFIVE = ADD(TWO)(THREE)\nemit(FIVE)\n\n'*****'\n\n\nThe last missing operator of our computational system multiplication. Multiplication should feel a lot like nested functions you see often in programming.\n\ndef MULT(a):  # Our first number, which is always a function\n    def outer(b):  # Our second number, which is always a function\n        def inner(f):  # The function we want to do a*b times\n            return b(a(f))  # do f, a times, and do that b times\n        return inner\n    return outer\n\nSIX = MULT(TWO)(THREE)\nemit(SIX)\n\n'******'\n\n\nAgain, we can represent MULT as a lambda:\n\nMULT = lambda a : lambda b : lambda f : b(a(f))\n\nSIX = MULT(TWO)(THREE)\nemit(SIX)\n\n'******'\n\n\n\n\nUsing Our Computer\nWe’ve now defined everything necessary to implement our square_sum function in the Lambda Calculus. Let’s build it here from these basic principles. We want to calculate square_sum(5, 2).\n\nZERO = lambda f : lambda x : x\nINCREMENT = lambda n : lambda f : lambda x : f(n(f)(x))\nADD = lambda a : lambda b: b(INCREMENT)(a)\nMULT = lambda a : lambda b : lambda f : b(a(f))\n\nsquare_sum = lambda a : lambda b : ADD(MULT(a)(a))(MULT(b)(b))\n\nTWO = ADD(INCREMENT(ZERO))(INCREMENT(ZERO))\nFIVE = INCREMENT(ADD(TWO)(TWO))\n\nRESULT = square_sum(FIVE)(TWO)\n\nAnd that’s it! Using nothing but single-argument lambda functions, we’ve successfully defined non-negative integers, the addition and multiplication operators, and the square-sum function. It’s a little hard to visualize, but the actual answer is calcuated in our RESULT variable. We can output it to our metaphorical printer:\n\nemit(RESULT)\n\n'*****************************'\n\n\nOur printer has output 29 asterisks! Pretty cool!\n\n\nWhat’s Next?\nOur system barely scratches the surface, but you can continue to implement more operators, comparators, control flow, and everything else you might need for a full computer. I highly recommend consulting the references at the top of the post for further reading!\n\n\nLicense\nCopyright (c) 2022, Matt Hodges\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of Exploring the Lambda Calculus with Python nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "posts/2024-08-08-spline-pchip/index.html",
    "href": "posts/2024-08-08-spline-pchip/index.html",
    "title": "Spline Versus PCHIP",
    "section": "",
    "text": "Let’s say you’ve got some data points and you make a scatterplot:\n\n\n\n\n\n\n\n\n\nYou might say great! and call it a day. But what if we want to see the behavior of the data between these points? Linear interpolation is a simple way to connect the dots:\n\n\n\n\n\n\n\n\n\nAnd now at this point you might say great! and call it a day. Or, you might decide that you can do better than linear interpolation. That sure does look like a sine curve. But you’re working with a collection of discrete points, and you wouldn’t want to erroneously just plot a sine function. Instead, you can reach for a smoother interpolation function, such as a spline:\n\n\n\n\n\n\n\n\n\nThe term “spline” refers to a wide class of functions involving interpolation and smoothing. In data viz, we often see the basis spline (or, B-spline). Think of spline interpolation like a flexible ruler that bends to pass smoothly through all your data points, but in doing so, it might sometimes bend too much or too little. Sometimes the spline overshoots, introducing peaks or valleys that weren’t there in the original data.\n\n\n\n\n\n\n\n\n\nSometimes this is okay! Depending on your data, a spline may be ideal for generating a very smooth curve, especially when smoothness is more critical than accurately interpolating between every data point. And when the underlying function is oscillatory, a spline can capture the movement between points quite accurately. But real-world data is often not oscillatory.\nLet’s say you’ve got a month’s worth of observed temperatures recorded in the Austin area:\n\n\n\n\n\n\n\n\n\nAnd because temperatures exist on a continuous distribution, we could do a simple linear interpolation to articulate the rates of change between points:\n\n\n\n\n\n\n\n\n\nBut temperatures are unlikely to ascend or descend on linear gradients, so we could also try a spline:\n\n\n\n\n\n\n\n\n\nThat’s a bit more natural, but it looks a bit weird, too. Unlike our sine wave sampling from before, the data points here are of real, observed, daily maximum temperatures. So it’s a little strange that the fit curve overshoots and undershoots those known values. The interpolation is smooth, but the shape of the data has not been preserved.\n\n\n\n\n\n\n\n\n\nWhile a spline produces smooth curves, the artifacts of overshooting, undershooting, or unwanted oscillations between data points can misrepresent what the data actually says. Fortunately, we have another option: the PCHIP, or Piecewise Cubic Hermite Interpolating Polynomial. Hermite refers to a method of interpolating data points where both the function values and the derivatives at those points are matched.\nA PCHIP preserves the shape of the data and avoids oscillations. The monotonicity (increasing or decreasing trend) of the data is preserved, ensuring no overshoots between data points. I like to think of PCHIP as a hand that firmly (but not rigidly) guides a curve through the data points without allowing any unnecessary dips or rises.\n\n\n\n\n\n\n\n\n\nLooks good! This results in a curve that better captures the shape of the function, especially when the slope information is critical. In our case, the slope is critical. It makes no sense to have a positive slope (overshooting) between points, when the next value decreased.\nBut PCHIP isn’t always better than Spline. Let’s apply a PCHIP interpolation to the oscillating data from before:\n\n\n\n\n\n\n\n\n\nIt’s not wrong, it’s just a little weird and lumpy. It’s a curve that connects the dots, but it somewhat lost the true movement between points.\nPCHIP can aggressively flattened near local extrema. When you need to capture those local extrema — as we did in our temperature plots — PCHIP works well. When you need to capture the smooth movements of oscillatory data, Spline works well. Sometimes it’s fairly intuitive what you need. Sometimes you need to plot it to really see which works better. Other times it takes more thought.\nConsider the nature of your data. If your data is smooth and continuous, like a waveform or a gradient, spline interpolation might work well. If your data has sharp changes or you need to preserve the natural shape of the data without introducing artifacts, PCHIP might be the better choice. In practical applications like elections modeling, financial forecasting, or engineering metrics, the choice can have significant implications.\nGraphs!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I am currently the Executive Director of Zinc Labs, a political innovation lab at Zinc Collective that houses the organization’s strategic work in Democratic technology and pilot programs. Through our network of campaigns, committees, vendors, donors, and subject matter experts, we incubate and invest in innovative new programs across the ecosystem. We prioritize investing in technology and people to enable collaborative experimentation, technical execution, and hypothesis testing.\nI sit on the Advisory Board of Quiller, an Artificial Intelligence copilot that helps Democrats draft and deploy high quality, effective fundraising content. In this capacity, I contribute product, technology, and political guidance to the Quiller leadership team.\nI sit on the Advisory Board of Higher Ground Labs, an accelerator that invests in early-stage political tech companies. In this capacity, I contribute strategic guidance to the Higher Ground Labs leadership team, and provide both political and technical advice to investment cohort companies.\nI was the Director of Engineering for President Joe Biden on his 2020 presidential campaign. I joined the campaign in July of 2019, and served in that role through the duration of the primary and general election cycles. I led a team of software, infrastructure, and security engineers, which was charged with delivering innovative new campaign tech for headquarters and states programs. We shipped dozens of internal and voter-facing products, including an in-house peer-to-peer texter, a relational organizing app, a real-time debate transcription service, a document and media ingestion and indexing library, a live donation tracking web service, a distributed soft-reporting platform, the JoeBiden.com web property, hundreds of ETL pipelines, and a cross-region data warehouse.\nI was a Senior Software Engineer on The Groundwork platform, which served as the application and infrastructure system that powered the 2016 presidential campaign of Secretary Hillary Clinton. Beginning in 2015, I was the primary engineer for multiple campaign-enabling web services for event signups, single-click donations, and peer-to-peer fundraising.\nI was an Infrastructure Engineer at Datadog where I architected and implemented the internal platform for Incident Response management. This tool eventually joined the suite of observability offerings available to customers. My team also implemented the organization’s first templated deployment pipeline for the organization’s global transition to Kubernetes.\nI was a Senior Mobile Engineer at LISNR, where I developed the product’s first iOS SDK for the ultrasonic data transport protocol. In 2014 the team joined the TechStars accelerator. This toolchain was originally designed to allow musicians to embed inaudbile data streams into their media. Over time, it became a location-aware second screen immersion platform for music festivals, professional sporting events, and feature films. It now serves as a payment protocol in partnership with VISA.\nI was a Senior Mobile Engineer and Scrum Master at Cardinal Solutions, with the team that built Vantiv Accept - a mobile credit card processing application. Envisioned as a competitor to Square, the application was deployed to retail and grocery point-of-sale systems across the country.\nI am a Named Inventor on an Augmented Reality Patent Application (US20140092241A1) for a “device and method for scanning of books and other items for order and inventory control”. We created a mobile application that scanned a shelf of books in real-time as a user viewed it through the screen. If it identified any items out of order, it overlayed the user’s view of the item with a red X to indicate a misplacement, and then povided directional guidance of where it should be moved.\nI have been an Election Night Reporter for Decision Desk HQ. I gathered live results from New Mexico and Ohio Boards of Elections offices to report real-time data as they were delivered from precincts. These results were featured on Vox and BuzzFeed election night coverage.\nI have been a frequent Open Source Contributor to OpenElections, which is creating the first free, comprehensive, standardized, linked set of election results data for the United States."
  },
  {
    "objectID": "index.html#work",
    "href": "index.html#work",
    "title": "About",
    "section": "",
    "text": "I am currently the Executive Director of Zinc Labs, a political innovation lab at Zinc Collective that houses the organization’s strategic work in Democratic technology and pilot programs. Through our network of campaigns, committees, vendors, donors, and subject matter experts, we incubate and invest in innovative new programs across the ecosystem. We prioritize investing in technology and people to enable collaborative experimentation, technical execution, and hypothesis testing.\nI sit on the Advisory Board of Quiller, an Artificial Intelligence copilot that helps Democrats draft and deploy high quality, effective fundraising content. In this capacity, I contribute product, technology, and political guidance to the Quiller leadership team.\nI sit on the Advisory Board of Higher Ground Labs, an accelerator that invests in early-stage political tech companies. In this capacity, I contribute strategic guidance to the Higher Ground Labs leadership team, and provide both political and technical advice to investment cohort companies.\nI was the Director of Engineering for President Joe Biden on his 2020 presidential campaign. I joined the campaign in July of 2019, and served in that role through the duration of the primary and general election cycles. I led a team of software, infrastructure, and security engineers, which was charged with delivering innovative new campaign tech for headquarters and states programs. We shipped dozens of internal and voter-facing products, including an in-house peer-to-peer texter, a relational organizing app, a real-time debate transcription service, a document and media ingestion and indexing library, a live donation tracking web service, a distributed soft-reporting platform, the JoeBiden.com web property, hundreds of ETL pipelines, and a cross-region data warehouse.\nI was a Senior Software Engineer on The Groundwork platform, which served as the application and infrastructure system that powered the 2016 presidential campaign of Secretary Hillary Clinton. Beginning in 2015, I was the primary engineer for multiple campaign-enabling web services for event signups, single-click donations, and peer-to-peer fundraising.\nI was an Infrastructure Engineer at Datadog where I architected and implemented the internal platform for Incident Response management. This tool eventually joined the suite of observability offerings available to customers. My team also implemented the organization’s first templated deployment pipeline for the organization’s global transition to Kubernetes.\nI was a Senior Mobile Engineer at LISNR, where I developed the product’s first iOS SDK for the ultrasonic data transport protocol. In 2014 the team joined the TechStars accelerator. This toolchain was originally designed to allow musicians to embed inaudbile data streams into their media. Over time, it became a location-aware second screen immersion platform for music festivals, professional sporting events, and feature films. It now serves as a payment protocol in partnership with VISA.\nI was a Senior Mobile Engineer and Scrum Master at Cardinal Solutions, with the team that built Vantiv Accept - a mobile credit card processing application. Envisioned as a competitor to Square, the application was deployed to retail and grocery point-of-sale systems across the country.\nI am a Named Inventor on an Augmented Reality Patent Application (US20140092241A1) for a “device and method for scanning of books and other items for order and inventory control”. We created a mobile application that scanned a shelf of books in real-time as a user viewed it through the screen. If it identified any items out of order, it overlayed the user’s view of the item with a red X to indicate a misplacement, and then povided directional guidance of where it should be moved.\nI have been an Election Night Reporter for Decision Desk HQ. I gathered live results from New Mexico and Ohio Boards of Elections offices to report real-time data as they were delivered from precincts. These results were featured on Vox and BuzzFeed election night coverage.\nI have been a frequent Open Source Contributor to OpenElections, which is creating the first free, comprehensive, standardized, linked set of election results data for the United States."
  },
  {
    "objectID": "index.html#media-appearances",
    "href": "index.html#media-appearances",
    "title": "About",
    "section": "Media & Appearances",
    "text": "Media & Appearances\n\n\nBig Tech Is Giving Campaigns Both the Venom and the Antidote for GenAI\n\nWired, 2024\n\n\n[Original] [Archive]\n\n\n\nAI Guidelines Earn Widespread Support Across the Democratic Political Community\n\nZinc Labs, 2024\n\n\n[Original] [Archive]\n\n\n\nPodcast: AI’s do’s and dont’s in politics\n\nThe Chuck Todd Podcast (Chuck ToddCast) | NBC News, 2024\n\n\n[Original] [Archive]\n\n\n\nPanel: A Responsible and Secure Approach to AI in Democratic Campaigns\n\nDefending Digital Campaigns & Microsoft, 2024\n\n\n[Original] [Archive]\n\n\n\nThe dos and don’ts of campaigning with AI\n\nThe Washington Post, 2024\n\n\n[Original] [Archive]\n\n\n\nQuick-Start AI Guidelines for Democratic CampaignsI\n\nZinc Labs, 2024\n\n\n[Original] [Archive]\n\n\n\nPanel: Threats vs Practicality - Realistic Solutions for Securing Campaigns\n\nGoogle and Defending Digital Campaigns Security Summit, 2024\n\n\n[Original] [Archive]\n\n\n\nPodcast: Can AI Help Meet Voters Where They Are?\n\nPolitics Is Everything, 2023\n\n\n[Original] [Archive]\n\n\n\nAI will change American elections, but not in the obvious way\n\nThe Economist, 2023\n\n\n[Original] [Archive]\n\n\n\n1 big thing: Democratic tech vendors go under the cyber microscope\n\nAxios, 2023\n\n\n[Original] [Archive]\n\n\n\nGenerative artificial intelligence tools ‘threaten democracy, reality’\n\nThe Courier-Mail, 2023\n\n\n[Original] [Archive]\n\n\n\nMatt Hodges, Political Technologist\n\nUses This, 2023\n\n\n[Original] [Archive]\n\n\n\nA Campaign Aide Didn’t Write That Email. A.I. Did.\n\nThe New York Times, 2023\n\n\n[Original] [Archive]\n\n\n\nWelcome Keynote\n\n2022 Election Tech Debrief, 2023\n\n\n[Original] [Archive]\n\n\n\nKeynote: Tech Innovation Comes From Those Who Build It\n\nCampaignTech Innovation Summit, 2022\n\n\n[Original]\n\n\n\nPanel: Tech For Good\n\nUnified Jam SXSW, 2022\n\n\n[Original] [Archive]\n\n\n\nBuilding Campaign Tech For Early Adoption\n\nHigher Ground Labs, 2021\n\n\n[Original] [Archive]\n\n\n\nPanel: Securing the 2020 Presidential Campaign\n\nBSides Las Vegas, 2021\n\n\n[Original] [Archive]\n\n\n\nThe Urgent Need For Democratic Tech Talent\n\nCampaigns and Elections, 2021\n\n\n[Original] [Archive]\n\n\n\nPodcast: Building Political Technology\n\nThe Great Battlefield, 2021\n\n\n[Original] [Archive]\n\n\n\n“Wear a Mask” In The Source Code\n\nThe Rachel Maddow Show | MSNBC, 2021\n\n\n[Archive]\n\n\n\nThe Biden administration quickly revamped the White House website. Here’s how.\n\nThe New York Times, 2021\n\n\n[Original] [Archive]\n\n\n\nButler County native, Miami grad played significant role in Biden campaign\n\nThe Journal-News, 2021\n\n\n[Original] [Archive]\n\n\n\n2018 Profile of Ohio’s 1st District\n\nDecision Desk HQ, 2018\n\n\n[Original] [Archive]\n\n\n\nThe other major hurdle for the Parkland teens: Turning out their peers\n\nThe Washington Post, 2018\n\n\n[Original] [Archive]\n\n\n\nPodcast: Can Zuck be trusted?\n\nTechieBytes, 2018\n\n\n[Original] [Archive]"
  }
]