[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Austin, Texas: Hot or Not?\n\n\nThis summer hasn‚Äôt felt as hot as last summer. I decided to find out if that was actually true.\n\n\n\n\n\n2024-07-30\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nHow Did Skannerz Work?\n\n\nOnly 90s kids are now adults who dig through patent filings to understand how their toys worked.\n\n\n\n\n\n2024-07-23\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nAmused Entirely To Death\n\n\nWhat if the imminent danger to our democracy isn‚Äôt just looming authoritarianism, but also our own insatiable appetite for distraction? Last week‚Äôs Republican National Convention provided a stark reminder of this unsettling threat.\n\n\n\n\n\n2024-07-20\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nBIDEN: Binary Inference Dictionaries for Electoral NLP\n\n\nA compression-based binary classification technique that is fast at both training and inference on common CPU hardware in Python\n\n\n\n\n\n2023-10-01\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Lambda Calculus with Python\n\n\nSome basic ideas of the Lambda Calculus, and how to use it to implement a computation system in Python\n\n\n\n\n\n2022-07-17\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nThank you.\n\n\nWorking on the Biden Campaign was the opportunity of a lifetime.\n\n\n\n\n\n2020-11-10\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-10-01-BIDEN-binary-inference-dictionaries-for-electoral-nlp/index.html",
    "href": "posts/2023-10-01-BIDEN-binary-inference-dictionaries-for-electoral-nlp/index.html",
    "title": "BIDEN: Binary Inference Dictionaries for Electoral NLP",
    "section": "",
    "text": "This post is adapted from a Jupyter Notebook found on GitHub.\nBIDEN: Binary Inference Dictionaries for Electoral NLP demonstrates a compression-based binary classification technique that is fast at both training and inference on common CPU hardware in Python. It is largely built on the strategies presented by FTCC, which in turn, was a reaction to Low-Resource Text Classification: A Parameter-Free Classification Method with Compressors (the gzip method). Like FTCC, BIDEN is built atop of Zstandard (Zstd), which leverages dictionary compression. Zstd dictionary compression seeds a compressor with sample data, so that it can efficiently compress small data (~1 KB) of similar composition. Seeding the compressor dictionaries acts as our ‚Äútraining‚Äù method for the model.\nThe BIDEN model was trained on the ElectionEmails 2020 data set ‚Äî a database of over 900,000 political campaign emails from the 2020 US election cycle. In compliance with the data set‚Äôs terms, the training data is NOT provided with this repository. If you would like to train the BIDEN model yourself, you can request a copy of the data for free. The BIDEN model was trained on corpus_v1.0.\n\nTraining and Classification\nBoth training and inference for BIDEN are fast and simple.\nThe model consists of two Zstd compressors, one optimized for Democratic emails and one optimzed for Republican emails. Each is built upon a compression dictionary. Each compression dictionary is seeded with training sample emails from its respective party.\nClassification (inference) is achieved by compressing a test sample with both the Democratic and Republican compressors. Whichever compressor achieves a higher compression ratio on the test sample text is considered the inferred label.\n\n\nCleaning the Training Data\nThe ElectionEmails 2020 data set is a CSV. The model consideres two columns: party_affiliation and body_text. BIDEN is only concerned with binary classification for Democratic and Republican labeling.\nThe two requirements defined in requirements.txt are Pandas and zstandard:\npandas==2.1.*\nzstandard==0.21.* \nStart by reading in the data. Since the model is only working with two columns, drop any record that doesn‚Äôt contain both. Also filter the data to only consider Democratic or Republican emails for the binary classificaiton.\nNote: this assumes you have the ElectionEmails 2020 data saved at the relative path data/corpus_v1.0.csv.\n\nfrom enum import Enum\n\nimport pandas as pd\nimport zstandard\n\nfields = {\n    'body_text': str,\n    'party_affiliation': str,\n}\n\ndf = pd.read_csv(\n    'data/corpus_v1.0.csv',\n    sep=',',\n    usecols=list(fields.keys()),\n    dtype=fields,\n)\n\ndf.drop_duplicates(inplace=True)\n\nd_df = df[df.party_affiliation == \"Democratic Party\"].dropna()\nr_df = df[df.party_affiliation == \"Republican Party\"].dropna()\n\nprint(f'D Samples: {len(d_df.index)}')\nprint(f'R Samples: {len(r_df.index)}')\n\nD Samples: 127194\nR Samples: 36788\n\n\nThere are significantly more Democratic samples than Republican samples, so take a random subset of the former.\n\nmax_data = min(len(d_df.index), len(r_df.index))\nd_df = d_df.sample(\n    n=max_data,\n    random_state=9001  # random seed set for reproducibility \n).reset_index(drop=True)\n\nr_df = r_df.sample(\n    n=max_data,\n    random_state=9001  # random seed set for reproducibility \n).reset_index(drop=True)\n\nprint(f'D Samples: {len(d_df.index)}')\nprint(f'R Samples: {len(r_df.index)}')\n\nD Samples: 36788\nR Samples: 36788\n\n\nNow divide the data into training and test subsets, at an 80/20 split.\n\nd_train_df = d_df.sample(frac=0.8, random_state=9001)  # random seed set for reproducibility \nd_test_df = d_df.drop(d_train_df.index)\n\nr_train_df = r_df.sample(frac=0.8, random_state=9001)  # random seed set for reproducibility \nr_test_df = r_df.drop(r_train_df.index)\n\nprint(f'Democratic Training Samples: {len(d_train_df.index)}')\nprint(f'Democratic Test Samples: {len(d_test_df.index)}')\nprint(f'Republican Training Samples: {len(r_train_df.index)}')\nprint(f'Republican Test Samples: {len(r_test_df.index)}')\n\nDemocratic Training Samples: 29430\nDemocratic Test Samples: 7358\nRepublican Training Samples: 29430\nRepublican Test Samples: 7358\n\n\n\n\nThe BIDEN model\nThe model consistes of two core methods: train() and classify() :\n\nclass BIDEN():\n    \"\"\"\n    Binary Inference Dictionaries for Electoral NLP (BIDEN)\n\n    This class allows you to train a model for classifying political content into\n    Democratic or Republican categories based on compression ratios.\n\n    Attributes:\n        Classification (enum): An enumeration of political classifications (DEMOCRATIC, REPUBLICAN).\n    \"\"\"\n    class Classification(Enum):\n        \"\"\"\n        Enumeration of political classifications.\n\n        Attributes:\n            DEMOCRATIC (int): Represents Democratic political content.\n            REPUBLICAN (int): Represents Republican political content.\n        \"\"\"\n        DEMOCRATIC = 1\n        REPUBLICAN = 2\n        \n    def __init__(self, encoding: str = 'utf-8'):\n        \"\"\"\n        Initialize the BIDEN model.\n\n        This constructor initializes the BIDEN model with empty compressors.\n\n        Args:\n            encoding (str, optional): The character encoding of the input data. Defaults to 'utf-8'.\n            \n        Returns:\n            BIDEN: An instance of the BIDEN class.\n        \"\"\"\n        self.d_compressor = None\n        self.d_compressor = None\n        self.encoding = encoding\n\n    @property\n    def trained(self) -&gt; bool:\n        \"\"\"\n        Check if the BIDEN model is trained.\n\n        Returns:\n            bool: True if both Democratic and Republican compressors are trained, False otherwise.\n        \"\"\"\n        return bool(self.d_compressor and self.r_compressor)\n\n    def train(self,\n              d_training_data: str,\n              r_training_data: str,\n              compression_level: int = 15,\n             ) -&gt; bool:\n        \"\"\"\n        Train the BIDEN model.\n\n        Args:\n            d_training_data (str): Democratic training data.\n            r_training_data (str): Republican training data.\n            compression_level (int, optional): The compression level. Defaults to 15.\n\n        Returns:\n            bool: True if training is successful, False otherwise.\n        \"\"\"        \n        d_dictionary = zstandard.ZstdCompressionDict(\n            d_training_data.encode(self.encoding),\n            dict_type=zstandard.DICT_TYPE_RAWCONTENT\n        )\n        d_dictionary.precompute_compress(level=compression_level)\n        self.d_compressor = zstandard.ZstdCompressor(dict_data=d_dictionary)\n\n        r_dictionary = zstandard.ZstdCompressionDict(\n            r_training_data.encode(self.encoding),\n            dict_type=zstandard.DICT_TYPE_RAWCONTENT\n        )\n        r_dictionary.precompute_compress(level=compression_level)\n        self.r_compressor = zstandard.ZstdCompressor(dict_data=r_dictionary)\n\n        return self.trained\n\n    def classify(self, sample: str) -&gt; Classification:\n        \"\"\"\n        Classify a sample based on compression ratios.\n\n        Args:\n            sample (str): The sample text to classify.\n\n        Returns:\n            Classification: The classification (DEMOCRATIC or REPUBLICAN).\n        \n        Raises:\n            RuntimeError: If the model is not trained.\n        \"\"\"\n        if not self.trained:\n            raise RuntimeError(\"Attempted to classify with a model that is not yet trained.\")\n        \n        encoded_sample = sample.encode(self.encoding)\n        original_length = len(encoded_sample)\n        d_compressed_length = len(self.d_compressor.compress(encoded_sample))\n        d_ratio = d_compressed_length / original_length\n        r_compressed_length = len(self.r_compressor.compress(encoded_sample))\n        r_ratio = r_compressed_length / original_length\n\n        if r_ratio &lt; d_ratio:\n            return BIDEN.Classification.REPUBLICAN\n\n        return BIDEN.Classification.DEMOCRATIC\n\n\n\nTrain the Model\nTo train the model, we pass the entirety of the Democratic and Republican texts to construct prefix dictionaries. Prefix dictionaries allow compression operations to reference raw data within the dictionary. Once we have two compressors instantiated and pre-seeded with our training data, the model is trained. This is fast. On my 2.6 GHz 6-Core Intel Core i7, this takes roughly 30 seconds.\n\nd_combined_text = '\\n'.join(d_train_df.body_text)\nr_combined_text = '\\n'.join(r_train_df.body_text)\n\nmodel = BIDEN()\nmodel.train(d_combined_text, r_combined_text)\n\nTrue\n\n\n\n\nClassification\nNow, we can classify our test data. We could loop through each set, but let‚Äôs combine and shuffle them together first, and loop in one go. We‚Äôll also convert the party affiliation strings 'Democratic Party', and 'Republican Party' into our model‚Äôs enum values:\n\ncombined_test_df = pd.concat(\n    [d_test_df, r_test_df],\n    ignore_index=True,\n    sort=False\n).sample(\n    frac=1,\n    random_state=9001,  # random seed set for reproducibility\n).reset_index(drop=True)\n\ncombined_test_df['party_affiliation'] = combined_test_df['party_affiliation'].replace(\n    to_replace=['Democratic Party', 'Republican Party'],\n    value=[BIDEN.Classification.DEMOCRATIC, BIDEN.Classification.REPUBLICAN]\n)\n\nnum_correct = 0\nfor row in combined_test_df.itertuples():\n    actual_label = row.party_affiliation\n    inferred_label = model.classify(row.body_text)\n\n    if inferred_label == actual_label:\n        num_correct += 1\n\nprint(f'Classification Success Rate: {((num_correct / len(combined_test_df.index))*100):.1f}%')\n\nClassification Success Rate: 98.9%\n\n\n98.9% is a shockingly high success rate for such a simple classification method!\n\n\nAnother Email Data Set\nLet‚Äôs see how it performs with emails from another data set. Derek Willis maintains a Datasette of over 150,000 campaign emails. Let‚Äôs grab 100 samples of each party from that collection, and see how they perform:\n\nbase_url = 'https://political-emails.herokuapp.com/emails.csv?sql='\nd_query = 'select body, party from emails where party = \"D\" limit 100;'\nr_query = 'select body, party from emails where party = \"R\" limit 100;'\n\nmap = {\n    ' ': '+',\n    ',': '%2C',\n    '=': '%3D',\n    '\"': '%22',\n    ';': '%3B',\n}\n\nfor symbol, code in map.items():\n    d_query = d_query.replace(symbol, code)\n    r_query = r_query.replace(symbol, code)\n\nd_url = base_url + d_query\nr_url = base_url + r_query\n\nd_dw_df = pd.read_csv(d_url)\nr_dw_df = pd.read_csv(r_url)\n\ncombined_dw_df = pd.concat(\n    [d_dw_df, r_dw_df],\n    ignore_index=True,\n    sort=False\n).sample(\n    frac=1,\n    random_state=9001,  # random seed set for reproducibility\n).reset_index(drop=True)\n\ncombined_dw_df['party'] = combined_dw_df['party'].replace(\n    to_replace=['D', 'R'],\n    value=[BIDEN.Classification.DEMOCRATIC, BIDEN.Classification.REPUBLICAN]\n)\n\nprint('DW Sample:')\ncombined_dw_df.head(10)\n\nDW Sample:\n\n\n\n\n\n\n\n\n\nbody\nparty\n\n\n\n\n0\nHey Peter!!! You know our campaign is made by,...\nClassification.DEMOCRATIC\n\n\n1\nhttps://www.jahanahayes.com/ [https://www.jaha...\nClassification.DEMOCRATIC\n\n\n2\nHi there, it‚Äôs storytime: I developed a keen n...\nClassification.DEMOCRATIC\n\n\n3\nWe‚Äôre contacting a select group of patriots fo...\nClassification.REPUBLICAN\n\n\n4\nPeter ‚Äì You need to watch this. CLICK HERE OR ...\nClassification.REPUBLICAN\n\n\n5\nPeter, you may have seen me asking for your ol...\nClassification.DEMOCRATIC\n\n\n6\nDo you want an Official Mugshot Mug? (24-hour ...\nClassification.REPUBLICAN\n\n\n7\nhttps://secure.actblue.com/donate/cdp-footer?r...\nClassification.DEMOCRATIC\n\n\n8\n[ https://act.katieporter.com/go/14559?t=1001&...\nClassification.DEMOCRATIC\n\n\n9\nI hope I made you proud fighting for you at th...\nClassification.REPUBLICAN\n\n\n\n\n\n\n\n\nnum_correct = 0\nfor row in combined_dw_df.itertuples():\n    actual_label = row.party\n    inferred_label = model.classify(row.body)\n\n    if inferred_label == actual_label:\n        num_correct += 1\n\nprint(f'Classification Success Rate: {((num_correct / len(combined_dw_df.index))*100):.1f}%')\n\nClassification Success Rate: 93.0%\n\n\n93% is still quite good considering that all we‚Äôre doing is compression!\n\n\nClassifying Tweets\nThe Twitter API is basically useless these days, so I scrolled the timelines of Mike Pence (R) and Gavin Newsom (D), and copy+paste‚Äôd 5 tweets from each. It‚Äôs a tiny sample, and not really random, but it‚Äôs neat to see how well it does:\n\npence_tweets = [\n    # https://twitter.com/Mike_Pence/status/1707882018258751915\n    \"Today, we applaud the Eighth Circuit's decision, \" \\\n    \"which is an important step in the fight to uphold and protect \" \\\n    \"the rights of parents and families in Linn-Mar. A family is the \" \\\n    \"single best unit to protect children, and we must continue to do \" \\\n    \"everything we can to empower parents over bureaucrats. The strength \" \\\n    \"of our nation is tied to the strength of our families, and we will \" \\\n    \"not stand idly by as the Radical Left attempts to indoctrinate our \" \\\n    \"children behind parents‚Äô backs.\",\n    # https://twitter.com/Mike_Pence/status/1707472823269392643\n    \"The cause of Life is the calling of our time \" \\\n    \"and I couldn‚Äôt be more proud to have played a role in the administration \" \\\n    \"that appointed three of the justices that overturned Roe v. Wade and \" \\\n    \"returned the question of abortion to the states and the American people.\",\n    \"Republicans are facing a Time for Choosing. \" \\\n    # https://twitter.com/Mike_Pence/status/1707241587460186214\n    \"We have to choose whether or not we‚Äôre going to stay on the path \" \\\n    \"that has defined our movement since the days of Ronald Reagan and \" \\\n    \"through the Trump-Pence years or whether we‚Äôre going to follow \" \\\n    \"the siren song of populism unmoored to Conservative principles.\",\n    # https://twitter.com/Mike_Pence/status/1704132623617122719\n    \"I am for working Americans and free enterprise. These businesses \" \\\n    \"make their decisions, but at the end the of the day these businesses \" \\\n    \"are responding to the heavy hand of the green new deal agenda of \" \\\n    \"Joe Biden and the Democrats in Washington, DC.\",\n    # https://twitter.com/Mike_Pence/status/1703887286641873137\n    \"We were the first country to sanction Chinese leaders for building \" \\\n    \"concentration camps in Xinjiang and for undermining democracy in Hong Kong. \" \\\n    \"And we stood up to years of trade abuses, and imposed historic tariffs \" \\\n    \"to bring China to the negotiating table.\"\n]\n\n[model.classify(t) for t in pence_tweets]\n\n[&lt;Classification.REPUBLICAN: 2&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;]\n\n\n\nnewsom_tweets = [\n    # https://twitter.com/GavinNewsom/status/1700615276667294035\n    \"When people ask why I am introducing a Constitutional Amendment \" \\\n    \"on gun safety this is why. Not only has Congress stalled for YEARS on passing \" \\\n    \"common sense reforms -- judges across the country are tearing down laws that \" \\\n    \"Americans overwhelmingly support. Laws that keep us SAFE and keep guns out of \" \\\n    \"the hands of dangerous criminals. We have to push back\",\n    # # https://twitter.com/GavinNewsom/status/1689743766733877248\n    \"California will be sending search and rescue \" \\\n    \"teams to assist in Hawaii's recovery efforts. The wildfires and \" \\\n    \"devastation that Maui is experiencing is all too familiar and all \" \\\n    \"too horrifying. We stand at the ready to aid Hawaii in its time of need.\",\n    # https://twitter.com/GavinNewsom/status/1679579172690329601\n    \"A school board in Temecula decided to reject a \" \\\n    \"textbook because it mentioned Harvey Milk. CA is stepping in. \" \\\n    \"We‚Äôre going to purchase the book for these students‚Äîthe same \" \\\n    \"one that hundreds of thousands of kids are already using. \" \\\n    \"If these extremist school board members won‚Äôt do their job, \" \\\n    \"we will ‚Äî and fine them for their incompetence.\",\n    # https://twitter.com/GavinNewsom/status/1650634702271942656\n    \"North Dakota GOP have decided to force women to give birth. Even victims of rape. \" \\\n    \"Meanwhile, they voted against providing school meals because child hunger isn't \" \\\n    \"\\\"the responsibility of the state.\\\"\" \\\n    \"Mandating birth is state responsibility. Helping feed those kids is not. Got it.\",\n    # https://twitter.com/GavinNewsom/status/1643745476662132737\n    \"Met with some librarians today while in Florida. \" \\\n    \"They shared with me the rich, diverse background of the \" \\\n    \"town and what's at stake if we ban our kids from learning our real history.\"\n]\n\n[model.classify(t) for t in newsom_tweets]\n\n[&lt;Classification.DEMOCRATIC: 1&gt;,\n &lt;Classification.DEMOCRATIC: 1&gt;,\n &lt;Classification.DEMOCRATIC: 1&gt;,\n &lt;Classification.DEMOCRATIC: 1&gt;,\n &lt;Classification.REPUBLICAN: 2&gt;]\n\n\nNeat! This small set classified 90% correctly. Further exploration with more robust Twitter data sets is warranted.\n\n\nClosing Thoughts\nEven after seeing the results, I still have a hard time believing that this works so well! It feels like it shouldn‚Äôt work at all. But, zooming out, there are a lot of relevant factors to consider. First, there just aren‚Äôt that many people writing campaign materials. It makes sense that word-choice and writing style would exhibit predictible patterns. Second, campaign emails have been A/B tested into oblivion, so there‚Äôs a systematic process that cranks out similar-sounding copy. Third, the recipients of these emails have largely self-sorted. This likely bolsters the expected structure and copy uniquely for each label. Ultimately, compression algorithms optimize on patterns and predictibility. What this shows us is that the two parties are uniquely predictible in their written communications.\nThe idea of classification by compression is not new; Russell and Norvig wrote about it in 1995 in the venerable Artificial Intelligence: A Modern Approach:\n\n\n\nClassification by data compression\n\n\nMore recently, the ‚Äúgzip beats BERT‚Äù paper got a lot of attention. What the BIDEN model demonstrates is that this technique is effective and likely generalizable on modern partisan texts.\nIt‚Äôs worth articulating again how fast and simple this method is. No GPUs. No Neural Networks. No N-grams. No transformers. No kNN.\nI think that‚Äôs pretty cool!\n\n\nLicense\nCopyright (c) 2023, Matt Hodges\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of BIDEN: Binary Inference Dictionaries for Electoral NLP nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "posts/2022-07-17-exploring-lambda-calculus-python/index.html",
    "href": "posts/2022-07-17-exploring-lambda-calculus-python/index.html",
    "title": "Exploring the Lambda Calculus with Python",
    "section": "",
    "text": "This post is adapted from a Jupyter Notebook found on GitHub.\nThis post explores some basic ideas of the Lambda Calculus, and how to use it to implement a computation system with it. We will define numbers and operators from scratch, and use that to implement the square_sum function.\nIf you‚Äôre new to the Lambda Calculus, or functional programming in general, you may wish to start with some of these resources:\n\nDavid Beazley‚Äôs Lambda Calculus from the Ground Up - PyCon 2019\n\nIf you‚Äôre someone who learns well by watching and listening, I highly recommend that you watch this talk. A significant portion of the concepts below come from watching this talk more than once.\n\nBen Eater‚Äôs Making a computer Turing complete\nLambda Calculus | Wikipedia\nCurrying | Wikipedia\n\nThis post assumes you are fairly familiar with Python and Python‚Äôs lambda expressions.\n\nRules of Our System\nThe Lambda Calculus asserts that any computational system can be implemented with a set of three simple rules: * You can define variables * You can define single-argument functions * You can call single-argument functions\nThat‚Äôs it. No numbers. No operators. No control flow. No data structures.\nI find it fascinating that with these very minimal concepts, the Lambda Calculus asserts that we can create a fully functional computer! This is, of course, a very minimal explanation of the rules of the Lambda Calculus, and I invite you to consult the references above for more information and formal definitions!\n\n\nThe Challenge\nUsing the rules described above, we want to create a system that can calculate the square-sum of any inputs. Again, we only have single-argument functions. That means we have no integers, no addition, and no multiplication. We‚Äôre going to have to create those using nothing but single-argument functions that accept single-argument functions as input and can only return single-argument functions.\nFor reference, consider the square_sum function, that may be written in Python as:\n\ndef square_sum(a, b):\n    return (a*a) + (b*b)\n\n\nsquare_sum(5, 2)\n\n29\n\n\n\nCurrying\nAs previously mentioned, our computation system requires that we can only create functions and those functions must accept one and only one argument. This may seem like a limiting requirement, but let‚Äôs take a look at what we can do with the idea of Currying ‚Äî a method for transforming multi-argument functions into a chain of single-argument functions. This allows us to re-write our Python implementation as:\n\ndef square_sum(a):\n    def inner(b):\n        return (a*a) + (b*b)\n    return inner\n\n\nsquare_sum(5)(2)\n\n29\n\n\nIn our curried version above, square_sum accepts the first argument, a and returns a function that accepts the second argument, b. We can then call that returned inner function to complete our calculation. Currying is a fundamental strategy for computation in the Lambda Calculus.\n\n\n\nOur Basic Building Block\nUnless you‚Äôre already familiary with the Lambda Calculus, or you‚Äôre a veteran of functional programming, you‚Äôre probaby very accustomed to computing by operating on state. You have data structures, or numbers, or bits, and you operate on them and then you persist new data structures, or numbers, or bits.\nOur concept of integers is a perfect example. As children, we learned that the concept of 3 can be represented by holding up three fingers on our hand, and seeing all three of them, and pointing to them. The Lambda Calculus asks us to adjust that concept away from state and towards behavior. Instead of holding up three fingers, what if we held up one finger three times. It may be harder for us see that idea of 3, but it is a representation of 3 nonetheless.\nSit with this idea of behavior representing integers, because behavior will be how we represent everything. And in our system, functions are behavior. Our function could be the act of holding up a finger, pressing a button, or anything else we need it to be.\nLet‚Äôs use that metaphor of pressing a button. The button press is our behavior, and behaviors are functions. And arguments are functions. And we can only return functions. So, let‚Äôs write that:\n\ndef button_press(f):\n    def g(x):\n        return f(x)\n    return g\n\nNot much to see here yet. In fact, our system isn‚Äôt designed to see anything. It‚Äôs designed to do computations within a given set of rules.\nWe‚Äôre designing a system of computation, and we can think about this system like instruction that run on a CPU. But we‚Äôre humans, and it‚Äôs helpful for us to be able to see the results of our computation in ways that we can understand. So, we‚Äôre going to introduce an external system that is not within the Lambda Calculus, but can interface with it. Think of this as a peripheral like a printer. It‚Äôs not used to do any of our computation. It can do special things that our CPU can‚Äôt do, and it‚Äôll connect to our system as a function, because our system can only work with functions.\nLet‚Äôs pretend our system has a printer attached that can only print the * character. We‚Äôll interface with it via an emit function.\nHere is our not-of-our-system emit function:\n\ndef emit(func):\n    def asterisk(x):\n        return f'{x}*'\n    return func(asterisk)('')\n\nThis is kindof strange. Our external emit function takes in some function and has an inner asterisk-generating function. Let‚Äôs hook it up to our button_press function:\n\nemit(button_press)\n\n'*'\n\n\nWhat just happened here? We call our emit function (external from our system) by passing in our button_press function (internal to our system). We did it one time, and it yielded a single *. Again, this is just a convenience interface so that we can see what‚Äôs going on, and isn‚Äôt necessary to do any of our actual computation.\n\n\nNumbers\nAbove we began to describe how functions, or behaviors, can represent numbers. A single call to button_press yielded some concept of 1. What if we didn‚Äôt think about it as one call to button_press anymore, but as the idea of one behavior:\n\ndef ONE(f):\n    def g(x):\n        return f(x)\n    return g\n\nemit(ONE)\n\n'*'\n\n\nIf you‚Äôve made it this far, you‚Äôre probably thinking, ‚ÄúHey, Python has a way to represent single-argument functions, and they‚Äôre called lambdas!‚Äù Let‚Äôs start using that instead of the expanded button_press function:\n\nONE = lambda f : lambda x : f(x)\n\nemit(ONE)\n\n'*'\n\n\nCool. So we know how to represent the concept of 1 using only single-argument functions. We can represent 2 by calling our function twice, because in our system numbers are behaviors:\n\nTWO = lambda f : lambda x: f(f(x))\n\nemit(TWO)\n\n'**'\n\n\nThis is all well and good, but we‚Äôre not really going to try to implement every single number are we? That wouldn‚Äôt make a very good computer. How can we represent all countable numbers?\nIf you look closely at our definitions above, ONE is a single call to f(), while TWO is f(f()). This means that if we‚Äôre at any given number, we can get to the next number by calling f() again. We can define an INCREMENT() function to do just that. I find it helpful to start by looking at this through the expanded Python functions first:\n\ndef ONE(f):  # f is the behavior we want to do\n    def g(x):  # x is the curried second argument\n        return f(x)\n    return g\n\n\ndef INCREMENT(n):  # n is the concept of the number we already have\n    def g(f):  # f is the behavior we want to do\n        def h(x):  # x is the curried second argument\n            return f(n(f)(x))  # we call f() again on our n(f)(x)\n        return h\n    return g\n\n\nemit(INCREMENT(ONE))\n\n'**'\n\n\nSpend some time stepping through the above code to understand it. We‚Äôre essentially wrapping nested functions as many times as we need to get to the next number. Once you‚Äôve wrapped your head around it, see that we can re-write the above as lambdas:\n\nONE = lambda f : lambda x : f(x)\n\nINCREMENT = lambda n : lambda f : lambda x : f(n(f)(x))\n\nTWO = INCREMENT(ONE)  # our calculated TWO from ONE\n\nemit(TWO)\n\n'**'\n\n\nIf we can calculate TWO from ONE, we can calculate THREE:\n\nTHREE = INCREMENT(TWO)\n\nemit(THREE)\n\n'***'\n\n\nPretty neat! We can keep doing this to infinity, either by saving values, or calculating them on the fly! But you may be wondering, what about ZERO? Well, we‚Äôve defined ONE as a single call to any behavior f(), so ZERO would simply be no calls to that behavior:\n\nZERO = lambda f : lambda x : x\n\nemit(ZERO)\n\n''\n\n\nSee how ZERO doesn‚Äôt call f() at all? What‚Äôs fun here is that we no longer need to have defined ONE, we can calculate it from ZERO!\n\nONE = INCREMENT(ZERO)\n\nemit(ONE)\n\n'*'\n\n\n\n\nOperators\nNow that we know we can represent numbers as function calls, let‚Äôs start working on math operators. We‚Äôve already introduced one critical operator, INCREMENT, and we can use that to introduce others. Let‚Äôs start with ADD. Addition is can be thought of as incrementing M times on a number N. For example, 2 + 3 could be described as incrementing 2, three times. Before we attempt to implement that in our system, let‚Äôs look again to how we would Curry this in Python:\n\ndef add(a):\n    def inner(b):\n        return a + b\n    return inner\n\nadd(2)(3)\n\n5\n\n\n\ndef ADD(a):  # Our first number, which is always a function\n    def inner(b):  # Our second number, which is always a function\n        return b(INCREMENT)(a)  # Increment a, b times\n    return inner\n\n\nFIVE = ADD(TWO)(THREE)\nemit(FIVE)\n\n'*****'\n\n\nSince everything is always a function, our numbers can be used not only as representations of calculations, but also as executors. Here‚Äôs our ADD as a lambda:\n\nADD = lambda a : lambda b: b(INCREMENT)(a)\n\nFIVE = ADD(TWO)(THREE)\nemit(FIVE)\n\n'*****'\n\n\nThe last missing operator of our computational system multiplication. Multiplication should feel a lot like nested functions you see often in programming.\n\ndef MULT(a):  # Our first number, which is always a function\n    def outer(b):  # Our second number, which is always a function\n        def inner(f):  # The function we want to do a*b times\n            return b(a(f))  # do f, a times, and do that b times\n        return inner\n    return outer\n\nSIX = MULT(TWO)(THREE)\nemit(SIX)\n\n'******'\n\n\nAgain, we can represent MULT as a lambda:\n\nMULT = lambda a : lambda b : lambda f : b(a(f))\n\nSIX = MULT(TWO)(THREE)\nemit(SIX)\n\n'******'\n\n\n\n\nUsing Our Computer\nWe‚Äôve now defined everything necessary to implement our square_sum function in the Lambda Calculus. Let‚Äôs build it here from these basic principles. We want to calculate square_sum(5, 2).\n\nZERO = lambda f : lambda x : x\nINCREMENT = lambda n : lambda f : lambda x : f(n(f)(x))\nADD = lambda a : lambda b: b(INCREMENT)(a)\nMULT = lambda a : lambda b : lambda f : b(a(f))\n\nsquare_sum = lambda a : lambda b : ADD(MULT(a)(a))(MULT(b)(b))\n\nTWO = ADD(INCREMENT(ZERO))(INCREMENT(ZERO))\nFIVE = INCREMENT(ADD(TWO)(TWO))\n\nRESULT = square_sum(FIVE)(TWO)\n\nAnd that‚Äôs it! Using nothing but single-argument lambda functions, we‚Äôve successfully defined non-negative integers, the addition and multiplication operators, and the square-sum function. It‚Äôs a little hard to visualize, but the actual answer is calcuated in our RESULT variable. We can output it to our metaphorical printer:\n\nemit(RESULT)\n\n'*****************************'\n\n\nOur printer has output 29 asterisks! Pretty cool!\n\n\nWhat‚Äôs Next?\nOur system barely scratches the surface, but you can continue to implement more operators, comparators, control flow, and everything else you might need for a full computer. I highly recommend consulting the references at the top of the post for further reading!\n\n\nLicense\nCopyright (c) 2022, Matt Hodges\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of Exploring the Lambda Calculus with Python nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "posts/2024-07-20-amused-entirely-to-death/index.html",
    "href": "posts/2024-07-20-amused-entirely-to-death/index.html",
    "title": "Amused Entirely To Death",
    "section": "",
    "text": "At this point there‚Äôs nothing novel in pointing out that news and politics has devolved into an entertainment competition. But I can‚Äôt become so numb to let last week‚Äôs Republican National Convention go without comment.\nI won‚Äôt get into detailed summaries or link to videos. The Republican National Convention, unsurprisingly, was rife with jingoism, xenophobia, and hate. But what stood out was a primetime performance on the final night:\n\n\n\nHulk Hogan ripping his shirt off during the 2024 Republican National Convention\n\n\nIf you missed the social media frenzy, the short version is Hulk Hogan took the stage during a primetime speech to say, among many pernicious things:\n\nBut what happened last week, when they took a shot at my hero, and they tried to kill the next president of the United States, enough was enough! And I said, ‚ÄòLet Trump-A-Mania run wild brother! Let Trump-A-Mania rule again!‚Äô\n\nAnd then he ripped off his shirt and the stadium of suited leaders of the Republican party lost their minds in cheers and applause. Never mind that pundits and Republican leaders assured us that ‚Äî after the attempted assassination of Donald Trump days prior ‚Äî this convention would be a message of national unity. Never mind whoever the they are that he‚Äôs talking about. Hulk Hogan gave the people what they wanted: a viral-worthy performance that makes you feel something when you press share.\nThis moment exemplified a broader issue that has been gradually intensifying. The disgraced former president, after all, is a reality TV character, epitomizing the entertainment-driven nature of modern politics. To note that is not to minimize the harm he has inflicted and will inflict if given another chance. But it‚Äôs an apt time to highlight a recurring misdiagnosis of modern Conservative power.\n\nOur Misdiagnosis of Conservative Power\nAs astute online big-brains, we‚Äôre frequently high-fiving ourselves for naming the Right‚Äôs methods and tactics as Orwellian (despite the fact that most people haven‚Äôt actually read Nineteen Eighty-Four). We get those small hits of dopamine by labeling our eroding rights as such. But by and large, power-building of the Trump era isn‚Äôt Orwellian at all. Just as Donald Trump himself isn‚Äôt Machiavellian at all (a core tenet from The Prince is a firm warning against flatterers ‚Äî Donald Trump could never). Yes, the Right does deploy assaults that could be lifted directly from Orwell or Bradbury ‚Äî look no further than the book-banning crusades or the ‚Äúdo not believe what you see‚Äù lies from the press briefing rooms. But when evaluating how we got here and why we‚Äôre stuck here, it‚Äôs instructive to look to Neil Postman‚Äôs observations in Amusing Ourselves to Death:\n\nBut we had forgotten that alongside Orwell‚Äôs dark vision, there was another - slightly older, slightly less well known, equally chilling: Aldous Huxley‚Äôs Brave New World. Contrary to common belief even among the educated, Huxley and Orwell did not prophesy the same thing. Orwell warns that we will be overcome by an externally imposed oppression. But in Huxley‚Äôs vision, no Big Brother is required to deprive people of their autonomy, maturity and history. As he saw it, people will come to love their oppression, to adore the technologies that undo their capacities to think. What Orwell feared were those who would ban books. What Huxley feared was that there would be no reason to ban a book, for there would be no one who wanted to read one. Orwell feared those who would deprive us of information. Huxley feared those who would give us so much that we would be reduced to passivity and egoism. Orwell feared that the truth would be concealed from us. Huxley feared the truth would be drowned in a sea of irrelevance. Orwell feared we would become a captive culture. Huxley feared we would become a trivial culture, preoccupied with some equivalent of the feelies, the orgy porgy, and the centrifugal bumblepuppy. As Huxley remarked in Brave New World Revisited, the civil libertarians and rationalists who are ever on the alert to oppose tyranny ‚Äúfailed to take into account man‚Äôs almost infinite appetite for distractions.‚Äù In 1984, Orwell added, people are controlled by inflicting pain. In Brave New World, they are controlled by inflicting pleasure. In short, Orwell feared that what we fear will ruin us. Huxley feared that what we desire will ruin us.\n\nI‚Äôm not particularly interested in arguing that ‚Äúwe‚Äôre living in a dystopia, actually‚Äù. Despite our collective addiction to devices that incessantly tell us that the world is terrible, I still believe things are getting better over time. And I largely reject the, ‚Äúno one has had it as bad as we have it‚Äù notions from my generational cohort. But we can only pursue the long arc of progress if we continue to care enough to do so. If I was architecting a #resist movement of 2024, it would be to resist the trivialization of political power.\nIt‚Äôs important to reflect on Huxley‚Äôs and Postman‚Äôs ideas, even if it makes us uncomfortable. So many people today claim they‚Äôve stopped consuming news altogether, but often they simply switch to more entertaining sources that don‚Äôt feel like homework. Consider this: how many of your friends can name a single Supreme Court justice without hints? You should start asking! This exercise, which I‚Äôve conducted socially, reveals fascinating results! These observations aren‚Äôt about intelligence ‚Äî they‚Äôre about priorities.\nAgain, I don‚Äôt think I‚Äôm pointing out anything novel here. Pundits analyze political events in terms of ‚Äúenergy‚Äù and base success on Nielsen viewership metrics. Matt Gaetz and Ted Cruz both have side gigs as podcast hosts. Marjorie Taylor Greene dresses up as Cruella de Vil to scream during the Statue of the Union.\n\n\n\nMarjorie Taylor Greene dressed up as Cruella de Vil to scream during the Statue of the Union\n\n\nIt‚Äôs all incredibly stupid. And it‚Äôs helpful to have an appropriate label for what‚Äôs been happening for a long time.\nSo, when Hulk Hogan took to the stage to frivolously transport the Right‚Äôs power-holders back to the 1980s while ripping off his shirt, exalting ‚ÄúTrump-A-Mania‚Äù (aptly named), it couldn‚Äôt be more clear that ambient Conservative power-building is Huxleyan, not Orwellian. We are amusing ourselves entirely to death.\nSeems bad."
  },
  {
    "objectID": "posts/2024-07-30-austin-hot-or-not/index.html",
    "href": "posts/2024-07-30-austin-hot-or-not/index.html",
    "title": "Austin, Texas: Hot or Not?",
    "section": "",
    "text": "I live in Austin, Texas. And last summer I felt like:\n\nBut this year, I‚Äôve felt more like:\n\nAnd earlier today I thought aloud to the group chat:\n\nI need to look up if Austin is being weird this year. Last year we got to like 50 consecutive days over 100. I don‚Äôt think we‚Äôve cracked 100 yet this year? Is there a website that answers this question?\n\nLast year the heat was so bad that local news outlets were keeping a running tally of how many consecutive days we broke 100¬∞F. It turns out we had 45 straight days of triple-digit heat in 2023, which began on July 8 and continued through August 22. I‚Äôm writing this on July 30, 2024 and I can‚Äôt recall a single day above 100¬∞F yet this year.\nYear-vs-year location based time series temperature data absolutely seems like a thing that should exist. Every month or so someone posts the updated doom surface air temperature graph, so surely I can just look that data up for my location, right?\nOn weather.gov you can get your own version of this graph. Pretty cool! But only for the current year:\n\nYou can also get tabular historic data within monthly windows that sometimes come as html and sometimes come as PDF. Also cool. But not convenient:\n\nAfter about 15 minutes of clicking, I couldn‚Äôt find a great way to generate the viz I was looking for; and I couldn‚Äôt get an easy data export. Maybe there‚Äôs a one-click way to get CSVs, but I didn‚Äôt find it. But after about 5 more minutes of googling, I did find the National Oceanic and Atmostpheric Administration‚Äôs Climate Data Online portal, which has an API.\n\nNCDC‚Äôs Climate Data Online (CDO) offers web services that provide access to current data. This API is for developers looking to create their own scripts or programs that use the CDO database of weather and climate data.\n\nHey, that sounds like me!\nThe API needs an access token. Wonderfully, all I needed to do was type in my email address and roughly one second later an access token landed in my inbox. LFG.\nFrom here it took a bit more reading to grok what data is available and in what formats, but I eventually found out about GHCND, or the Global Historical Climatology Network daily:\n\nThe Global Historical Climatology Network daily (GHCNd) is an integrated database of daily climate summaries from land surface stations across the globe. GHCNd is made up of daily climate records from numerous sources that have been integrated and subjected to a common suite of quality assurance reviews.\n\nThat sounds like it might contain what I‚Äôm looking for.\nNext, there are a lot of ways to filter this data by location, but stationid caught my attention. I found this list of GHCND stations and decided to go with AUSTIN BERGSTROM INTL AP because it‚Äôs the same location from the tabular data above. It has the identifier USW00013904.\nAfter a quick pip install requests pandas matplotlib and tossing my token into a NCDC_CDO_TOKEN environment variable, we‚Äôre ready to jam.\nFirst let‚Äôs get a function to grab some data. I‚Äôm intersted in comparing year over year, so let‚Äôs grab a year at a time.\n\nimport os\n\nimport matplotlib.patches as mpatches\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport requests\n\ndef get_max_temps(year, limit=366):\n    token = os.getenv(\"NCDC_CDO_TOKEN\")\n    start_date = f\"{year}-01-01\"\n    end_date = f\"{year}-12-31\"\n    url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n    params = {\n        \"datasetid\": \"GHCND\",\n        \"stationid\": \"GHCND:USW00013904\",\n        \"startdate\": start_date,\n        \"enddate\": end_date,\n        \"datatypeid\": \"TMAX\",  # max temp\n        \"units\": \"standard\",  # üá∫üá∏\n        \"limit\": limit,  \n    }\n    headers = {\n        \"token\": token  \n    }\n\n    response = requests.get(url, headers=headers, params=params)\n    data = response.json()\n    return data\n\nLet‚Äôs look at the first three:\nget_max_temps(2024, limit=3)\n{\n    \"metadata\": {\n        \"resultset\": {\n            \"offset\": 1,\n            \"count\": 209,\n            \"limit\": 3\n        }\n    },\n    \"results\": [\n        {\n            \"date\": \"2024-01-01T00:00:00\",\n            \"datatype\": \"TMAX\",\n            \"station\": \"GHCND:USW00013904\",\n            \"attributes\": \",,W,2400\",\n            \"value\": 58.0\n        },\n        {\n            \"date\": \"2024-01-02T00:00:00\",\n            \"datatype\": \"TMAX\",\n            \"station\": \"GHCND:USW00013904\",\n            \"attributes\": \",,W,2400\",\n            \"value\": 53.0\n        },\n        {\n            \"date\": \"2024-01-03T00:00:00\",\n            \"datatype\": \"TMAX\",\n            \"station\": \"GHCND:USW00013904\",\n            \"attributes\": \",,W,2400\",\n            \"value\": 51.0\n        }\n    ]\n}\nGreat! We can pull from the date and the value fields. Let‚Äôs grab all of 2024 and shove it into a DataFrame.\n\ndef to_df(data):\n    # Extract date and truncate off the time part\n    dates = [item[\"date\"][:10] for item in data[\"results\"]]\n\n    # Grab the max temp value for each date\n    max_temps = [item[\"value\"] for item in data[\"results\"]]\n\n    # Create a DataFrame\n    df = pd.DataFrame({\"date\": dates,\"max_temp\": max_temps})\n\n    # Set the `date` col as a datetime and make it the index\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    df.set_index(\"date\", inplace=True)\n    \n    return df\n\nQuick spot check:\n\ndf_2024 = to_df(get_max_temps(2024))\n\nprint(f\"Head:\\n{df_2024.head()}\")\nprint(f\"Tail:\\n{df_2024.tail()}\")\nprint(f\"Format:\\n{df_2024.dtypes}\")\n\nHead:\n            max_temp\ndate                \n2024-01-01      58.0\n2024-01-02      53.0\n2024-01-03      51.0\n2024-01-04      58.0\n2024-01-05      67.0\nTail:\n            max_temp\ndate                \n2024-07-23      82.0\n2024-07-24      89.0\n2024-07-25      88.0\n2024-07-26      89.0\n2024-07-27      86.0\nFormat:\nmax_temp    float64\ndtype: object\n\n\nAwesome. I‚Äôm writing this on 2024-07-30 and it‚Äôs got data up through 2024-07-27. Good enough for me!\nNow to actually get at what I was trying to do this whole time. I‚Äôm going to grab DataFrames for 2023 and 2024, and plot a time series of each.\n\ndf_2023 = to_df(get_max_temps(2023))\n\n# Adjust 2023 dates to match the 2024 index\n# This is how we shift the graph to overlap\n# If you don't do this, 2024 comes after, not on top of, 2023\ndf_2023.index = df_2023.index.map(lambda x: x.replace(year=2024))\n\n# Plot the data\nfig, ax = plt.subplots(figsize=(10, 6))\ndf_2023.plot(ax=ax, color=\"black\", legend=\"2023\")\ndf_2024.plot(ax=ax, color=\"red\", legend=\"2024\")\n\n# Sett x-axis to display month labels\nax.set_xticks(\n    pd.date_range(\n        start=df_2023.index.min(),\n        end=df_2023.index.max(),\n        freq='MS',\n    )\n)\nax.set_xticklabels(\n    pd.date_range(\n        start=df_2023.index.min(),\n        end=df_2023.index.max(),\n        freq='MS',\n    ).strftime('%B')\n)\n\n# Formatting\nblack_patch = mpatches.Patch(color=\"black\", label=\"2023\")\nred_patch = mpatches.Patch(color=\"red\", label=\"2024\")\nplt.legend(handles=[black_patch, red_patch])\nax.set_title(\"Max Daily Temperatures Recorded in the Austin-Bergstrom Airport Area\")\nplt.xticks(rotation=45)\n\nplt.show()\n\n\n\n\n\n\n\n\nSo that‚Äôs pretty cool. Most of 2024 has tracked 2023 for daily high temperatures. But not July. July has been weirdly cooler than last year. Or last year was weirdly hotter than normal.\nActually, let‚Äôs see if we can tease that out. Let‚Äôs grab the past 10 years.\n\nimport time\n\n# Create a dictionary of year:DataFrame\nyear_dfs = {}\nfor year in range(2014, 2024):\n    year_dfs[year] = to_df(get_max_temps(year))\n    # Be a nice internet citizen and wait between requests\n    time.sleep(5)\n\n# Adjust pre-2024 dates to match the 2024 index\n# This is how we shift the graph to overlap\n# If you don't do this, 2024 comes after, not on top of, 2023\nfor df in year_dfs.values():\n    df.index = df.index.map(lambda x: x.replace(year=2024))\n\n# Plot the data\nfig, ax = plt.subplots(figsize=(10, 6))\nfor year, df in year_dfs.items():\n    if year == 2023:\n         df.plot(ax=ax, label=\"2023\", color=\"gold\")\n    else:\n        df.plot(ax=ax, color=\"gray\")\ndf_2024.plot(ax=ax, label=\"2024\", color=\"red\")\n\n# Sett x-axis to display month labels\nax.set_xticks(\n    pd.date_range(\n        start=year_dfs[2023].index.min(),\n        end=year_dfs[2023].index.max(),\n        freq='MS'\n    )\n)\nax.set_xticklabels(\n    pd.date_range(\n        start=year_dfs[2023].index.min(),\n        end=year_dfs[2023].index.max(),\n        freq='MS',\n    ).strftime('%B')\n)\n\n# Formatting\nax.set_title(\n    \"Max Daily Temperatures Recorded in the Austin-Bergstrom Airport Area 2014 - 2024\"\n)\nplt.xticks(rotation=45)\ngold_patch = mpatches.Patch(color=\"gold\", label=\"2023\")\nred_patch = mpatches.Patch(color=\"red\", label=\"2024\")\nplt.legend(handles=[gold_patch, red_patch])\n\nplt.show()\n\n\n\n\n\n\n\n\nSeems like Austin‚Äôs 2023 summer was on the hotter side, and so far the 2024 summer is on the cooler side.\nAnd was I correct that we haven‚Äôt cracked 100 yet this year?\n\nprint(df_2024[df_2024[\"max_temp\"] &gt;= 100])\n\n            max_temp\ndate                \n2024-07-02     100.0\n2024-07-05     100.0\n\n\nComputers!"
  },
  {
    "objectID": "posts/2024-07-23-how-did-skannerz-work/index.html",
    "href": "posts/2024-07-23-how-did-skannerz-work/index.html",
    "title": "How Did Skannerz Work?",
    "section": "",
    "text": "This post is a redux from a now-deleted social media thread. It felt too important to let bit rot.\nIf you‚Äôre a Millennial of a certain age, or perhaps a Baby Boomer who raised Millennials,1 you might remember the 2001 toy Skannerz by Radica. It was a gotta-catch-em-all game that involved scanning real-world barcodes to collect monsters and objects, and to battle other Skannerz. It was a hand-held gadget toy back when consumer electronics were still weird and fun and we had more products than just iPhone. I had a blue one. It looked like this:\nThe toy/game had an A+ premise: alien monsters transported down to earth and decided to hide inside of the barcodes on products all around your home (or, more annoyingly to your parents, all around the grocery store). Your job was to scan every barcode you could get your hands on, fight and capture the alien monsters, and then fight the monsters your friends collected. And to make the weirdest Pok√©mon ripoff complete: the Skannerz came in three colors ‚Äî red, blue, and green ‚Äî that could only collect monsters of their associated ‚Äútribes‚Äù. This really good commercial explains:\nBecause I was already a major dork at 11 years old, I was intrigued by how the device worked. How did it go from barcode to monster? There was no way it was talking to a server (although I did imagine the world‚Äôs greatest PHPMyAdmin at the time). I guessed that it had every possible barcode referenced internally. But that‚Äôs not quite correct. It was a little more clever than that.\nBut frirst, a quick primer on barcodes. There are many variations; this is a UPC Version A ‚Äî very common in the United States. It has a basic specification: that first digit way to the left is the product type (sometimes called a number system). The next five digits identify the manufacturer. The next five identify the product. And at the end is a checksum digit. The details of how to implement the spec aren‚Äôt all too important for our Skannerz exploration.\nOkay, back to the Skannerz game. As mentioned above, there were 3 different ‚Äútribes‚Äù, identified by which color scanning device you had. And there were 126 total monsters. So each tribe could capture 42 monsters. If you wanted to catch ‚Äôem all you needed to buy all three. Business!\nYou could also collect non-monster items from barcodes. And some barcodes healed your injured monsters. Again, these toys had no wireless communication (it was 2001!) so all of the logic for item or monster identification was baked right into the device. But how?\nThe Skannerz patent is conveniently revealing!2 The device only cares about the ‚Äúproduct‚Äù section (denoted below as 1315). If the first digit is 0-5, you‚Äôve scanned a monster. 6-9, you‚Äôve scanned an item. Digits 3, 4, and 5 identify the item/monster.\nIf the first digit in the barcode‚Äôs product code is 0 - 5, we‚Äôre in Monster Mode.\nWe‚Äôve got 1000 possible values (000-999 across digits 3, 4, and 5 in our product code) to identify 126 monsters. The patent goes on to explain how the magic of division solves this problem:\n\\[\n\\frac{1000}{126} = 7.94\n\\]\nAnd there was much rejoicing.\nThe range of numbers from 000 to 007 correspond to the first monster in Tribe 1, 008 to 015 correspond to the first monster in Tribe 2, and so on.\nThe patent then goes on to address the fact that 126 doesn‚Äôt divide well into 1000, and that 7.94 is not an integer. We only follow this eight-stepping until we get through the 124th monster, and then:\nNow, if the first digit in the barcode‚Äôs produt code is 6 - 9, we‚Äôre in Item Mode.\nSimilarly, there were 24 items in the game + 1 for healing. So 25 items. Again, we‚Äôve got 1000 values to work with:\n\\[\n\\frac{1000}{25} = 40\n\\]\nSo a range of 40 numbers can be used to define each item. Item 1 corresponds to the range of numbers from 000 through 039, Item 2 corresponds to the range of numbers from 040 through 079, and so on. And great news: 40 is an integer.\nQuick aside: the UPC Version A codec above is the the only format outlined in the Skannerz patent. But the patent also burries this little nugget:\nWhat does that mean? It literally says nothing else about what invention is being claimed there, but good on the Radica lawyers for planting a flag I guess? Maybe the Skannerz Commander, which I never had, rolled its own encryption algorithm?\nBut that‚Äôs really it! If you knew this encoding scheme, and had access to a printer, you could collect all the monsters and items pretty quickly. Anyone else remember Barcode Mill? Of course people knew; there were unofficial barcode books you could buy to help you complete your collection. But where‚Äôs the fun in that?\nThanks for indulging my dork nostalgia. I look forward to the Greta Gerwig adaptation."
  },
  {
    "objectID": "posts/2024-07-23-how-did-skannerz-work/index.html#footnotes",
    "href": "posts/2024-07-23-how-did-skannerz-work/index.html#footnotes",
    "title": "How Did Skannerz Work?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGenerational cohort discourse is stupid.‚Ü©Ô∏é\nYou don‚Äôt need to be a lawyer to read a patent. They can be very interesting! This one had cartoon drawings!‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2020-11-10-thank-you/index.html",
    "href": "posts/2020-11-10-thank-you/index.html",
    "title": "Thank you.",
    "section": "",
    "text": "It can‚Äôt be a cliche because it actually can‚Äôt be over-said: working on the Biden Campaign has been both the hardest and most rewarding experience of my career. It‚Äôs a rare opportunity to work on something you care deeply about, with amazing people, and to succeed. I said it in 2016, and in 2018, and I‚Äôll say it again in 2020: the tech was never the point. I‚Äôm immensely proud of the work we did. The world will never fully understand the mountains that this scrappy team was able to move.\nTo those who invited me in: thank you. To those who pushed me: thank you. To those who pushed with me: thank you.\nWhat‚Äôs next? I‚Äôm going to sleep for a while. I don‚Äôt know what‚Äôs after that, but I won‚Äôt be stepping away from the fight for democracy, justice, and a better world."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I am currently the Executive Director of Zinc Labs, a political innovation lab at Zinc Collective that houses the organization‚Äôs strategic work in Democratic technology and pilot programs. Through our network of campaigns, committees, vendors, donors, and subject matter experts, we incubate and invest in innovative new programs across the ecosystem. We prioritize investing in technology and people to enable collaborative experimentation, technical execution, and hypothesis testing.\nI sit on the Advisory Board of Quiller, an Artificial Intelligence copilot that helps Democrats draft and deploy high quality, effective fundraising content. In this capacity, I contribute product, technology, and political guidance to the Quiller leadership team.\nI sit on the Advisory Board of Higher Ground Labs, an accelerator that invests in early-stage political tech companies. In this capacity, I contribute strategic guidance to the Higher Ground Labs leadership team, and provide both political and technical advice to investment cohort companies.\nI was the Director of Engineering for President Joe Biden on his 2020 presidential campaign. I joined the campaign in July of 2019, and served in that role through the duration of the primary and general election cycles. I led a team of software, infrastructure, and security engineers, which was charged with delivering innovative new campaign tech for headquarters and states programs. We shipped dozens of internal and voter-facing products, including an in-house peer-to-peer texter, a relational organizing app, a real-time debate transcription service, a document and media ingestion and indexing library, a live donation tracking web service, a distributed soft-reporting platform, the JoeBiden.com web property, hundreds of ETL pipelines, and a cross-region data warehouse.\nI was a Senior Software Engineer on The Groundwork platform, which served as the application and infrastructure system that powered the 2016 presidential campaign of Secretary Hillary Clinton. Beginning in 2015, I was the primary engineer for multiple campaign-enabling web services for event signups, single-click donations, and peer-to-peer fundraising.\nI was an Infrastructure Engineer at Datadog where I architected and implemented the internal platform for Incident Response management. This tool eventually joined the suite of observability offerings available to customers. My team also implemented the organization‚Äôs first templated deployment pipeline for the organization‚Äôs global transition to Kubernetes.\nI was a Senior Mobile Engineer at LISNR, where I developed the product‚Äôs first iOS SDK for the ultrasonic data transport protocol. In 2014 the team joined the TechStars accelerator. This toolchain was originally designed to allow musicians to embed inaudbile data streams into their media. Over time, it became a location-aware second screen immersion platform for music festivals, professional sporting events, and feature films. It now serves as a payment protocol in partnership with VISA.\nI was a Senior Mobile Engineer and Scrum Master at Cardinal Solutions, with the team that built Vantiv Accept - a mobile credit card processing application. Envisioned as a competitor to Square, the application was deployed to retail and grocery point-of-sale systems across the country.\nI am a Named Inventor on an Augmented Reality Patent Application (US20140092241A1) for a ‚Äúdevice and method for scanning of books and other items for order and inventory control‚Äù. We created a mobile application that scanned a shelf of books in real-time as a user viewed it through the screen. If it identified any items out of order, it overlayed the user‚Äôs view of the item with a red X to indicate a misplacement, and then povided directional guidance of where it should be moved.\nI have been an Election Night Reporter for Decision Desk HQ. I gathered live results from New Mexico and Ohio Boards of Elections offices to report real-time data as they were delivered from precincts. These results were featured on Vox and BuzzFeed election night coverage.\nI have been a frequent Open Source Contributor to OpenElections, which is creating the first free, comprehensive, standardized, linked set of election results data for the United States."
  },
  {
    "objectID": "index.html#work",
    "href": "index.html#work",
    "title": "About",
    "section": "",
    "text": "I am currently the Executive Director of Zinc Labs, a political innovation lab at Zinc Collective that houses the organization‚Äôs strategic work in Democratic technology and pilot programs. Through our network of campaigns, committees, vendors, donors, and subject matter experts, we incubate and invest in innovative new programs across the ecosystem. We prioritize investing in technology and people to enable collaborative experimentation, technical execution, and hypothesis testing.\nI sit on the Advisory Board of Quiller, an Artificial Intelligence copilot that helps Democrats draft and deploy high quality, effective fundraising content. In this capacity, I contribute product, technology, and political guidance to the Quiller leadership team.\nI sit on the Advisory Board of Higher Ground Labs, an accelerator that invests in early-stage political tech companies. In this capacity, I contribute strategic guidance to the Higher Ground Labs leadership team, and provide both political and technical advice to investment cohort companies.\nI was the Director of Engineering for President Joe Biden on his 2020 presidential campaign. I joined the campaign in July of 2019, and served in that role through the duration of the primary and general election cycles. I led a team of software, infrastructure, and security engineers, which was charged with delivering innovative new campaign tech for headquarters and states programs. We shipped dozens of internal and voter-facing products, including an in-house peer-to-peer texter, a relational organizing app, a real-time debate transcription service, a document and media ingestion and indexing library, a live donation tracking web service, a distributed soft-reporting platform, the JoeBiden.com web property, hundreds of ETL pipelines, and a cross-region data warehouse.\nI was a Senior Software Engineer on The Groundwork platform, which served as the application and infrastructure system that powered the 2016 presidential campaign of Secretary Hillary Clinton. Beginning in 2015, I was the primary engineer for multiple campaign-enabling web services for event signups, single-click donations, and peer-to-peer fundraising.\nI was an Infrastructure Engineer at Datadog where I architected and implemented the internal platform for Incident Response management. This tool eventually joined the suite of observability offerings available to customers. My team also implemented the organization‚Äôs first templated deployment pipeline for the organization‚Äôs global transition to Kubernetes.\nI was a Senior Mobile Engineer at LISNR, where I developed the product‚Äôs first iOS SDK for the ultrasonic data transport protocol. In 2014 the team joined the TechStars accelerator. This toolchain was originally designed to allow musicians to embed inaudbile data streams into their media. Over time, it became a location-aware second screen immersion platform for music festivals, professional sporting events, and feature films. It now serves as a payment protocol in partnership with VISA.\nI was a Senior Mobile Engineer and Scrum Master at Cardinal Solutions, with the team that built Vantiv Accept - a mobile credit card processing application. Envisioned as a competitor to Square, the application was deployed to retail and grocery point-of-sale systems across the country.\nI am a Named Inventor on an Augmented Reality Patent Application (US20140092241A1) for a ‚Äúdevice and method for scanning of books and other items for order and inventory control‚Äù. We created a mobile application that scanned a shelf of books in real-time as a user viewed it through the screen. If it identified any items out of order, it overlayed the user‚Äôs view of the item with a red X to indicate a misplacement, and then povided directional guidance of where it should be moved.\nI have been an Election Night Reporter for Decision Desk HQ. I gathered live results from New Mexico and Ohio Boards of Elections offices to report real-time data as they were delivered from precincts. These results were featured on Vox and BuzzFeed election night coverage.\nI have been a frequent Open Source Contributor to OpenElections, which is creating the first free, comprehensive, standardized, linked set of election results data for the United States."
  },
  {
    "objectID": "index.html#media-appearances",
    "href": "index.html#media-appearances",
    "title": "About",
    "section": "Media & Appearances",
    "text": "Media & Appearances\n\n\nBig Tech Is Giving Campaigns Both the Venom and the Antidote for GenAI\n\nWired, 2024\n\n\n[Original] [Archive]\n\n\n\nAI Guidelines Earn Widespread Support Across the Democratic Political Community\n\nZinc Labs, 2024\n\n\n[Original] [Archive]\n\n\n\nPodcast: AI‚Äôs do‚Äôs and dont‚Äôs in politics\n\nThe Chuck Todd Podcast (Chuck ToddCast) | NBC News, 2024\n\n\n[Original] [Archive]\n\n\n\nPanel: A Responsible and Secure Approach to AI in Democratic Campaigns\n\nDefending Digital Campaigns & Microsoft, 2024\n\n\n[Original] [Archive]\n\n\n\nThe dos and don‚Äôts of campaigning with AI\n\nThe Washington Post, 2024\n\n\n[Original] [Archive]\n\n\n\nQuick-Start AI Guidelines for Democratic CampaignsI\n\nZinc Labs, 2024\n\n\n[Original] [Archive]\n\n\n\nPanel: Threats vs Practicality - Realistic Solutions for Securing Campaigns\n\nGoogle and Defending Digital Campaigns Security Summit, 2024\n\n\n[Original] [Archive]\n\n\n\nPodcast: Can AI Help Meet Voters Where They Are?\n\nPolitics Is Everything, 2023\n\n\n[Original] [Archive]\n\n\n\nAI will change American elections, but not in the obvious way\n\nThe Economist, 2023\n\n\n[Original] [Archive]\n\n\n\n1 big thing: Democratic tech vendors go under the cyber microscope\n\nAxios, 2023\n\n\n[Original] [Archive]\n\n\n\nGenerative artificial intelligence tools ‚Äòthreaten democracy, reality‚Äô\n\nThe Courier-Mail, 2023\n\n\n[Original] [Archive]\n\n\n\nMatt Hodges, Political Technologist\n\nUses This, 2023\n\n\n[Original] [Archive]\n\n\n\nA Campaign Aide Didn‚Äôt Write That Email. A.I. Did.\n\nThe New York Times, 2023\n\n\n[Original] [Archive]\n\n\n\nWelcome Keynote\n\n2022 Election Tech Debrief, 2023\n\n\n[Original] [Archive]\n\n\n\nKeynote: Tech Innovation Comes From Those Who Build It\n\nCampaignTech Innovation Summit, 2022\n\n\n[Original]\n\n\n\nPanel: Tech For Good\n\nUnified Jam SXSW, 2022\n\n\n[Original] [Archive]\n\n\n\nBuilding Campaign Tech For Early Adoption\n\nHigher Ground Labs, 2021\n\n\n[Original] [Archive]\n\n\n\nPanel: Securing the 2020 Presidential Campaign\n\nBSides Las Vegas, 2021\n\n\n[Original] [Archive]\n\n\n\nThe Urgent Need For Democratic Tech Talent\n\nCampaigns and Elections, 2021\n\n\n[Original] [Archive]\n\n\n\nPodcast: Building Political Technology\n\nThe Great Battlefield, 2021\n\n\n[Original] [Archive]\n\n\n\n‚ÄúWear a Mask‚Äù In The Source Code\n\nThe Rachel Maddow Show | MSNBC, 2021\n\n\n[Archive]\n\n\n\nThe Biden administration quickly revamped the White House website. Here‚Äôs how.\n\nThe New York Times, 2021\n\n\n[Original] [Archive]\n\n\n\nButler County native, Miami grad played significant role in Biden campaign\n\nThe Journal-News, 2021\n\n\n[Original] [Archive]\n\n\n\n2018 Profile of Ohio‚Äôs 1st District\n\nDecision Desk HQ, 2018\n\n\n[Original] [Archive]\n\n\n\nThe other major hurdle for the Parkland teens: Turning out their peers\n\nThe Washington Post, 2018\n\n\n[Original] [Archive]\n\n\n\nPodcast: Can Zuck be trusted?\n\nTechieBytes, 2018\n\n\n[Original] [Archive]"
  }
]